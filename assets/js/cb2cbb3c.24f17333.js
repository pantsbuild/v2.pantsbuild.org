"use strict";(self.webpackChunkpantsbuild_org=self.webpackChunkpantsbuild_org||[]).push([["366692"],{740734(e,t,n){n.r(t),n.d(t,{assets:()=>a,contentTitle:()=>l,default:()=>c,frontMatter:()=>o,metadata:()=>r,toc:()=>u});var r=n(791563),s=n(886070),i=n(848193);let o={title:"Testing plugins",sidebar_position:9},l,a={},u=[{value:"Approach 1: normal unit tests",id:"approach-1-normal-unit-tests",level:2},{value:"Approach 2: <code>run_rule_with_mocks()</code> (unit tests for rules)",id:"approach-2-run_rule_with_mocks-unit-tests-for-rules",level:2},{value:"How to mock some common types",id:"how-to-mock-some-common-types",level:3},{value:"Approach 3: <code>RuleRunner</code> (integration tests for rules)",id:"approach-3-rulerunner-integration-tests-for-rules",level:2},{value:"Setting up the <code>RuleRunner</code>",id:"setting-up-the-rulerunner",level:3},{value:"Setting up the content and BUILD files",id:"setting-up-the-content-and-build-files",level:3},{value:"Setting options",id:"setting-options",level:3},{value:"Running your rules",id:"running-your-rules",level:3},{value:"Testing <code>@goal_rule</code>s",id:"testing-goal_rules",level:3},{value:"Approach 4: <code>run_pants()</code> (integration tests for Pants)",id:"approach-4-run_pants-integration-tests-for-pants",level:2},{value:"Debugging integration tests",id:"debugging-integration-tests",level:3}];function d(e){let t={a:"a",admonition:"admonition",code:"code",em:"em",h2:"h2",h3:"h3",hr:"hr",li:"li",mdxAdmonitionTitle:"mdxAdmonitionTitle",p:"p",pre:"pre",ul:"ul",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.p,{children:"How to verify your plugin works."}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsx)(t.p,{children:"There are four main approaches to testing your plugin, ranging in terms of scope (unit vs. integration test). You may mix-and-match between these approaches."}),"\n",(0,s.jsxs)(t.p,{children:["All approaches use ",(0,s.jsx)(t.a,{href:"https://docs.pytest.org/en/latest/",children:"Pytest"}),"-style tests, rather than ",(0,s.jsx)(t.a,{href:"https://docs.python.org/3/library/unittest.html",children:(0,s.jsx)(t.code,{children:"unittest"})}),"-style tests."]}),"\n",(0,s.jsxs)(t.p,{children:["You must also install the distribution ",(0,s.jsx)(t.code,{children:"pantsbuild.pants.testutil"}),". We recommend using the ",(0,s.jsxs)(t.a,{href:"/2.28/docs/writing-plugins/overview",children:[(0,s.jsx)(t.code,{children:"pants_requirements"})," target to do this"]}),"."]}),"\n",(0,s.jsx)(t.h2,{id:"approach-1-normal-unit-tests",children:"Approach 1: normal unit tests"}),"\n",(0,s.jsx)(t.p,{children:"Often, you can factor out normal Python functions from your plugin that do not use the Rules API. These helpers can be tested like you would test any other Python code."}),"\n",(0,s.jsxs)(t.p,{children:["For example, some Pants rules take the type ",(0,s.jsx)(t.code,{children:"InterpreterConstraints"})," as input. ",(0,s.jsx)(t.code,{children:"InterpreterConstraints"})," has a factory method ",(0,s.jsx)(t.code,{children:"merge_constraint_sets()"})," that we can test through a normal unit test."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'def test_merge_interpreter_constraints() -> None:\n    # A & B => A & B\n    assert InterpreterConstraints.merge_constraint_sets(\n        [["CPython==2.7.*"], ["CPython==3.6.*"]]\n    ) == ["CPython==2.7.*,==3.6.*"]\n\n    # A | B => A | B\n    assert InterpreterConstraints.merge_constraint_sets(\n        [["CPython==2.7.*", "CPython==3.6.*"]]\n    ) == ["CPython==2.7.*", "CPython==3.6.*"]\n'})}),"\n",(0,s.jsxs)(t.p,{children:["This approach can be especially useful for testing the Target API, such as testing custom validation you added to a ",(0,s.jsx)(t.code,{children:"Field"}),"."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'def test_timeout_validation() -> None:\n    with pytest.raises(InvalidFieldException):\n        PythonTestTimeoutField(-100, Address("demo"))\n    with pytest.raises(InvalidFieldException):\n        PythonTestTimeoutField(0, Address("demo"))\n    assert PythonTestTimeoutField(5, Address("demo")).value == 5\n'})}),"\n",(0,s.jsxs)(t.admonition,{type:"note",children:[(0,s.jsxs)(t.mdxAdmonitionTitle,{children:["How to create a ",(0,s.jsx)(t.code,{children:"Target"})," in-memory"]}),(0,s.jsxs)(t.p,{children:["For Approaches #1 and #2, you will often want to pass a ",(0,s.jsx)(t.code,{children:"Target"})," instance to your test, such as a ",(0,s.jsx)(t.code,{children:"PythonTestTarget"})," instance."]}),(0,s.jsxs)(t.p,{children:["To create a ",(0,s.jsx)(t.code,{children:"Target"})," instance, choose which subclass you want, then pass a dictionary of the values you want to use, followed by an ",(0,s.jsx)(t.code,{children:"Address"})," object. The dictionary corresponds to what you'd put in the BUILD file; any values that you leave off will use their default values."]}),(0,s.jsxs)(t.p,{children:["The ",(0,s.jsx)(t.code,{children:"Address"})," constructor's first argument is the path to the BUILD file; you can optionally define ",(0,s.jsx)(t.code,{children:"target_name: str"})," if it is not the default ",(0,s.jsx)(t.code,{children:"name"}),"."]}),(0,s.jsxs)(t.p,{children:["For example, given this target definition for ",(0,s.jsx)(t.code,{children:"project/app:tgt"}),":"]}),(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'python_test(\n    name="tgt",\n    source="app_test.py",\n    timeout=120,\n)\n'})}),(0,s.jsx)(t.p,{children:"We would write:"}),(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'tgt = PythonTestTarget(\n    {"source": "app_test.py", "timeout": 120},\n    Address("project/app", target_name="tgt"),\n)\n'})}),(0,s.jsxs)(t.p,{children:["Note that we did not put ",(0,s.jsx)(t.code,{children:'"name": "tgt"'})," in the dictionary. ",(0,s.jsx)(t.code,{children:"name"})," is a special field that does not use the Target API. Instead, pass the ",(0,s.jsx)(t.code,{children:"name"})," to the ",(0,s.jsx)(t.code,{children:"target_name"})," argument in the ",(0,s.jsx)(t.code,{children:"Address"})," constructor."]}),(0,s.jsxs)(t.p,{children:["For Approach #3, you should instead use ",(0,s.jsx)(t.code,{children:"rule_runner.write_files()"})," to write a BUILD file, followed by ",(0,s.jsx)(t.code,{children:"rule_runner.get_target()"}),"."]}),(0,s.jsxs)(t.p,{children:["For Approach #4, you should use ",(0,s.jsx)(t.code,{children:"setup_tmpdir()"})," to set up BUILD files."]})]}),"\n",(0,s.jsxs)(t.h2,{id:"approach-2-run_rule_with_mocks-unit-tests-for-rules",children:["Approach 2: ",(0,s.jsx)(t.code,{children:"run_rule_with_mocks()"})," (unit tests for rules)"]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.code,{children:"run_rule_with_mocks()"})," will run your rule's logic, but with each argument to your ",(0,s.jsx)(t.code,{children:"@rule"})," provided explicitly by you and with mocks for any ",(0,s.jsx)(t.code,{children:"await Get"}),"s. This means that the test is fully mocked; for example, ",(0,s.jsx)(t.code,{children:"run_rule_with_mocks()"})," will not actually run a ",(0,s.jsx)(t.code,{children:"Process"}),", nor will it use the file system operations. This is useful when you want to test the inlined logic in your rule, but usually, you will want to use Approach #3."]}),"\n",(0,s.jsxs)(t.p,{children:["To use ",(0,s.jsx)(t.code,{children:"run_rule_with_mocks"}),", pass the ",(0,s.jsx)(t.code,{children:"@rule"})," as its first arg, then ",(0,s.jsx)(t.code,{children:"rule_args=[arg1, arg2, ...]"})," in the same order as the arguments to the ",(0,s.jsx)(t.code,{children:"@rule"}),"."]}),"\n",(0,s.jsx)(t.p,{children:"For example:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'from pants.engine.rules import rule\nfrom pants.testutil.rule_runner import run_rule_with_mocks\n\n\n@rule\nasync def int_to_str(i: int) -> str:\n    return str(i)\n\n\ndef test_int_to_str() -> None:\n    result: str = run_rule_with_mocks(int_to_str, rule_args=[42], mock_gets=[])\n    assert result == "42"\n'})}),"\n",(0,s.jsxs)(t.p,{children:["If your ",(0,s.jsx)(t.code,{children:"@rule"})," has any ",(0,s.jsx)(t.code,{children:"await Get"}),"s or ",(0,s.jsx)(t.code,{children:"await Effect"}),"s, set the argument ",(0,s.jsx)(t.code,{children:"mock_gets=[]"})," with ",(0,s.jsx)(t.code,{children:"MockGet"}),"/",(0,s.jsx)(t.code,{children:"MockEffect"})," objects corresponding to each of them. A ",(0,s.jsx)(t.code,{children:"MockGet"})," takes three arguments: ",(0,s.jsx)(t.code,{children:"output_type: type"}),", ",(0,s.jsx)(t.code,{children:"input_types: tuple[type, ...]"}),", and ",(0,s.jsx)(t.code,{children:"mock: Callable[..., InputType]"}),", which is a function that takes an instance of each of the ",(0,s.jsx)(t.code,{children:"input_types"})," and returns a single instance of the ",(0,s.jsx)(t.code,{children:"output_type"}),"."]}),"\n",(0,s.jsxs)(t.p,{children:["For example, given this contrived rule to find all targets with ",(0,s.jsx)(t.code,{children:"sources"}),' with a certain filename included (find a "needle in the haystack"):']}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'from __future__ import annotations\n\nfrom dataclasses import dataclass\nfrom pathlib import PurePath\n\nfrom pants.engine.collection import Collection\nfrom pants.engine.rules import Get, MultiGet, rule\nfrom pants.engine.target import HydratedSources, HydrateSourcesRequest, SourcesField, Target\n\n\n@dataclass(frozen=True)\nclass FindNeedle:\n    """A request to find all targets with a `sources` file matching the `needle_filename`."""\n    targets: tuple[Target, ...]\n    needle_filename: str\n\n\n# We want to return a sequence of found `Target` objects. Rather than\n# returning `Targets`, we create a "newtype" specific to this rule.\nclass TargetsWithNeedle(Collection[Target]):\n    pass\n\n\n@rule\nasync def find_needle_in_haystack(find_needle: FindNeedle) -> TargetsWithNeedle:\n    all_hydrated_sources = await MultiGet(\n        [Get(HydratedSources, HydrateSourcesRequest(tgt.get(SourcesField))) for tgt in find_needle.targets]\n    )\n    return TargetsWithNeedle(\n        tgt\n        for tgt, hydrated_sources in zip(find_needle.targets, all_hydrated_sources)\n        if any(PurePath(fp).name == find_needle.needle_filename for fp in hydrated_sources.snapshot.files)\n    )\n'})}),"\n",(0,s.jsx)(t.p,{children:"We can write this test:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'from pants.engine.addresses import Address\nfrom pants.engine.fs import EMPTY_DIGEST, Snapshot\nfrom pants.engine.target import HydratedSources, HydrateSourcesRequest, Target, Sources\nfrom pants.testutil.rule_runner import MockGet, run_rule_with_mocks\n\nclass MockTarget(Target):\n    alias = "mock_target"\n    core_fields = (Sources,)\n\n\ndef test_find_needle_in_haystack() -> None:\n    tgt1 = MockTarget({}, Address("", target_name="t1"))\n    tgt2 = MockTarget({}, Address("", target_name="t2"))\n    tgt3 = MockTarget({}, Address("", target_name="t3"))\n    find_needles_request = FindNeedle(targets=(tgt1, tgt2, tgt3), needle_filename="needle.txt")\n\n    def mock_hydrate_sources(request: HydrateSourcesRequest) -> HydratedSources:\n        # Our rule only looks at `HydratedSources.snapshot.files`, so we mock all other fields. We\n        # include the file `needle.txt` for the target `:t2`, but no other targets.\n        files = (\n            ("needle.txt", "foo.txt")\n            if request.field.address.target_name == "t2"\n            else ("foo.txt", "bar.txt")\n        )\n        mock_snapshot = Snapshot(EMPTY_DIGEST, files=files, dirs=())\n        return HydratedSources(mock_snapshot, filespec={}, sources_type=None)\n\n    result: TargetsWithNeedle = run_rule_with_mocks(\n        find_needle_in_haystack,\n        rule_args=[find_needles_request],\n        mock_gets=[\n            MockGet(\n                output_type=HydratedSources,\n                input_types=(HydrateSourcesRequest,),\n                mock=mock_hydrate_sources,\n            )\n        ],\n    )\n    assert list(result) == [tgt2]\n'})}),"\n",(0,s.jsx)(t.h3,{id:"how-to-mock-some-common-types",children:"How to mock some common types"}),"\n",(0,s.jsxs)(t.p,{children:["See the above tooltip about how to create a ",(0,s.jsx)(t.code,{children:"Target"})," instance."]}),"\n",(0,s.jsxs)(t.p,{children:["If your rule takes a ",(0,s.jsx)(t.code,{children:"Subsystem"})," or ",(0,s.jsx)(t.code,{children:"GoalSubsystem"})," as an argument, you can use the utilities ",(0,s.jsx)(t.code,{children:"create_subsystem"})," and ",(0,s.jsx)(t.code,{children:"create_goal_subsystem"})," like below. Note that you must explicitly provide all options read by your ",(0,s.jsx)(t.code,{children:"@rule"}),"; the default values will not be used."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'from pants.backend.python.subsystems.setup import PythonSetup\nfrom pants.core.goals.fmt import FmtSubsystem\nfrom pants.testutil.option_util import create_goal_subsystem, create_subsystem\n\nmock_subsystem = create_subsystem(PythonSetup, interpreter_constraints=["CPython==3.8.*"])\nmock_goal_subsystem = create_goal_subsystem(FmtSubsystem, sep="\\n")\n'})}),"\n",(0,s.jsxs)(t.p,{children:["If your rule takes ",(0,s.jsx)(t.code,{children:"Console"})," as an argument, you can use the ",(0,s.jsx)(t.code,{children:"with_console"})," context manager like this:"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'from pants.testutil.option_util import create_options_bootstrapper\nfrom pants.testutil.rule_runner import mock_console, run_rule_with_mocks\n\ndef test_with_console() -> None:\n    with mock_console(create_options_bootstrapper()) as (console, stdio_reader):\n        result: MyOutputType = run_rule_with_mocks(my_rule, [..., console])\n        assert stdio_reader.get_stdout() == "expected stdout"\n        assert not stdio_reader.get_stderr()\n'})}),"\n",(0,s.jsxs)(t.p,{children:["If your rule takes ",(0,s.jsx)(t.code,{children:"Workspace"})," as an argument, first create a ",(0,s.jsx)(t.code,{children:"pants.testutil.rule_runner.RuleRunner()"})," instance in your individual test. Then, create a ",(0,s.jsx)(t.code,{children:"Workspace"})," object with ",(0,s.jsx)(t.code,{children:"Workspace(rule_runner.scheduler)"}),"."]}),"\n",(0,s.jsxs)(t.h2,{id:"approach-3-rulerunner-integration-tests-for-rules",children:["Approach 3: ",(0,s.jsx)(t.code,{children:"RuleRunner"})," (integration tests for rules)"]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.code,{children:"RuleRunner"})," allows you to run rules in an isolated environment, i.e. where you set up the rule graph and registered target types exactly how you want. ",(0,s.jsx)(t.code,{children:"RuleRunner"})," will set up your rule graph and create a temporary build root. This is useful for integration tests that are more isolated and faster than Approach #4."]}),"\n",(0,s.jsxs)(t.p,{children:["After setting up your isolated environment, you can run ",(0,s.jsx)(t.code,{children:"rule_runner.request(Output, [input1, input2])"}),", e.g. ",(0,s.jsx)(t.code,{children:"rule_runner.request(SourceFiles, [SourceFilesRequest([sources_field])])"})," or ",(0,s.jsx)(t.code,{children:'rule_runner.request(TargetsWithNeedle, [FindNeedle(targets, "needle.txt"])'}),'. This will cause Pants to "call" the relevant ',(0,s.jsx)(t.code,{children:"@rule"})," to get the output type."]}),"\n",(0,s.jsxs)(t.h3,{id:"setting-up-the-rulerunner",children:["Setting up the ",(0,s.jsx)(t.code,{children:"RuleRunner"})]}),"\n",(0,s.jsxs)(t.p,{children:["First, you must set up a ",(0,s.jsx)(t.code,{children:"RuleRunner"})," instance and activate the rules and target types you'll use in your tests. Set the argument ",(0,s.jsx)(t.code,{children:"target_types"})," with a list of the ",(0,s.jsx)(t.code,{children:"Target"})," types used in your tests, and set ",(0,s.jsx)(t.code,{children:"rules"})," with a list of all the rules used transitively."]}),"\n",(0,s.jsx)(t.p,{children:"This means that you must register the rules you directly wrote, and also any rules that they depend on. Pants will automatically register some core rules for you, but leaves off most of them for better isolation of tests. If you're missing some rules, the rule graph will fail to be built."}),"\n",(0,s.jsxs)(t.admonition,{title:"Confusing rule graph error?",type:"caution",children:[(0,s.jsxs)(t.p,{children:["It can be confusing figuring out what's wrong when setting up a ",(0,s.jsx)(t.code,{children:"RuleRunner"}),". We know the error messages are not ideal and are working on improving them."]}),(0,s.jsxs)(t.p,{children:["Please feel free to reach out on ",(0,s.jsx)(t.a,{href:"/community/members",children:"Slack"})," for help with figuring out how to get things working."]})]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:"from pants.backend.python.goals import pytest_runner\nfrom pants.backend.python.goals.pytest_runner import PythonTestFieldSet\nfrom pants.backend.python.util_rules import pex_from_targets\nfrom pants.backend.python.target_types import PythonSourceTarget, PythonTestTarget\nfrom pants.core.goals.test import TestResult\nfrom pants.testutil.rule_runner import QueryRule, RuleRunner\n\ndef test_example() -> None:\n    rule_runner = RuleRunner(\n        target_types=[PythonSourceTarget, PythonTestTarget],\n        rules=[\n            *pytest_runner.rules(),\n            *pex_from_targets.rules(),\n            QueryRule(TestResult, [PythonTestFieldSet])\n        ],\n    )\n"})}),"\n",(0,s.jsxs)(t.p,{children:["What's with the ",(0,s.jsx)(t.code,{children:"QueryRule"}),"? Normally, we don't use ",(0,s.jsx)(t.code,{children:"QueryRule"})," because we're using the ",(0,s.jsx)(t.em,{children:"asynchronous"})," version of the Rules API, and Pants is able to parse your Python code to see how your rules are used. However, with tests, we are using the ",(0,s.jsx)(t.em,{children:"synchronous"})," version of the Rules API, so we need to give a hint to the engine about what requests we're going to make. Don't worry about filling in the ",(0,s.jsx)(t.code,{children:"QueryRule"})," part yet. You'll add it later when writing ",(0,s.jsx)(t.code,{children:"rule_runner.request()"}),"."]}),"\n",(0,s.jsxs)(t.p,{children:["Each test should create its own distinct ",(0,s.jsx)(t.code,{children:"RuleRunner"})," instance. This is important for isolation between each test."]}),"\n",(0,s.jsxs)(t.p,{children:["It's often convenient to define a ",(0,s.jsx)(t.a,{href:"https://docs.pytest.org/en/stable/fixture.html",children:"Pytest fixture"})," in each test file. This allows you to share a common ",(0,s.jsx)(t.code,{children:"RuleRunner"})," setup, but get a new instance for each test."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:"import pytest\n\nfrom pants.testutil.rule_runner import RuleRunner\n\n@pytest.fixture\ndef rule_runner() -> RuleRunner:\n    return RuleRunner(target_types=[PythonSourceTarget], rules=[rule1, rule2])\n\n\ndef test_example1(rule_runner: RuleRunner) -> None:\n    rule_runner.write_files(...)\n    ...\n\n\ndef test_example2(rule_runner: RuleRunner) -> None:\n    rule_runner.write_files(...)\n    ...\n"})}),"\n",(0,s.jsxs)(t.p,{children:["If you want multiple distinct ",(0,s.jsx)(t.code,{children:"RuleRunner"})," setups in your file, you can define multiple Pytest fixtures."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:"import pytest\n\nfrom pants.testutil.rule_runner import RuleRunner\n\n@pytest.fixture\ndef first_rule_runner() -> RuleRunner:\n    return RuleRunner(rules=[rule1, rule2])\n\n\ndef test_example1(first_rule_runner: RuleRunner) -> None:\n    first_rule_runner.write_files(...)\n    ...\n\n\ndef test_example2(first_rule_runner: RuleRunner) -> None:\n    first_rule_runner.write_files(...)\n    ...\n\n\n@pytest.fixture\ndef second_rule_runner() -> RuleRunner:\n    return RuleRunner(rules=[rule3])\n\n\ndef test_example3(second_rule_runner: RuleRunner) -> None:\n    second_rule_runner.write_files(...)\n    ...\n"})}),"\n",(0,s.jsx)(t.h3,{id:"setting-up-the-content-and-build-files",children:"Setting up the content and BUILD files"}),"\n",(0,s.jsxs)(t.p,{children:["For most tests, you'll want to create files and BUILD files in your temporary build root. Use ",(0,s.jsx)(t.code,{children:"rule_runner.write_files(files: dict[str, str])"}),"."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'from pants.testutil.rule_runner import RuleRunner\n\ndef test_example() -> None:\n     rule_runner = RuleRunner()\n     rule_runner.write_files(\n         {\n             "project/app.py": "print(\'hello world!\')\\n",\n             "project/BUILD": "python_library()",\n         }\n     )\n'})}),"\n",(0,s.jsx)(t.p,{children:"This function will write the files to the correct location and also notify the engine that the files were created."}),"\n",(0,s.jsxs)(t.p,{children:["You can then use ",(0,s.jsx)(t.code,{children:"rule_runner.get_target()"})," to have Pants read the BUILD file and give you back the corresponding ",(0,s.jsx)(t.code,{children:"Target"}),"."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'from textwrap import dedent\n\nfrom pants.engine.addresses import Address\nfrom pants.testutil.rule_runner import RuleRunner\n\ndef test_example() -> None:\n     rule_runner = RuleRunner()\n     rule_runner.write_files({\n         "project/BUILD": dedent(\n             """\\\n             python_source(\n                 name="my_tgt",\n                 source="f.py",\n             """)\n         }\n     )\n     tgt = rule_runner.get_target(Address("project", target_name="my_tgt"))\n'})}),"\n",(0,s.jsxs)(t.p,{children:["To read any files that were created, use ",(0,s.jsx)(t.code,{children:"rule_runner.build_root"})," as the first part of the path to ensure that the correct directory is read."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'from pants.testutil.rule_runner import RuleRunner\n\ndef test_example() -> None:\n    rule_runner = RuleRunner()\n    rule_runner.write_files({"project/app.py": "print(\'hello world!\')\\n"})\n    assert Path(rule_runner.build_root, "project/app.py").read_text() == "print(\'hello world!\')\\n"\n'})}),"\n",(0,s.jsx)(t.h3,{id:"setting-options",children:"Setting options"}),"\n",(0,s.jsxs)(t.p,{children:["Often, you will want to set Pants options, such as activating a certain backend or setting a ",(0,s.jsx)(t.code,{children:"--config"})," option."]}),"\n",(0,s.jsxs)(t.p,{children:["To set options, call ",(0,s.jsx)(t.code,{children:"rule_runer.set_options()"})," with a list of the arguments, e.g. ",(0,s.jsx)(t.code,{children:'rule_runner.set_options(["--pytest-version=pytest>=6.0"])'}),". Global options will need to be set when constructing the ",(0,s.jsx)(t.code,{children:"rule_runner"})," using the ",(0,s.jsx)(t.code,{children:"bootstrap_args"})," parameter. For example, ",(0,s.jsx)(t.code,{children:"bootstrap_args=[\"--pants-ignore=['!/.normally_ignored/']\"]"})," will allow a test to read from a normally ignored directory, which can be useful for reading config files."]}),"\n",(0,s.jsxs)(t.p,{children:["You can also set the keyword argument ",(0,s.jsx)(t.code,{children:"env: dict[str, str]"}),". If the option starts with ",(0,s.jsx)(t.code,{children:"PANTS_"}),", it will change which options Pants uses. You can include any arbitrary environment variable here; some rules use the parent Pants process to read arbitrary env vars, e.g. the ",(0,s.jsx)(t.code,{children:"--test-extra-env-vars"})," option, so this allows you to mock the environment in your test. Alternatively, use the keyword argument ",(0,s.jsx)(t.code,{children:"env_inherit: set[str]"})," to set the specified environment variables using the test runner's environment, which is useful to set values like ",(0,s.jsx)(t.code,{children:"PATH"})," which may vary across machines."]}),"\n",(0,s.jsxs)(t.admonition,{type:"caution",children:[(0,s.jsxs)(t.mdxAdmonitionTitle,{children:["Calling ",(0,s.jsx)(t.code,{children:"rule_runner.set_options()"})," will override any options that were previously set."]}),(0,s.jsx)(t.p,{children:"You will need to register everything you want in a single call."})]}),"\n",(0,s.jsx)(t.h3,{id:"running-your-rules",children:"Running your rules"}),"\n",(0,s.jsxs)(t.p,{children:["Now that you have your ",(0,s.jsx)(t.code,{children:"RuleRunner"})," set up, along with any options and the content/BUILD files for your test, you can test that your rules work correctly."]}),"\n",(0,s.jsxs)(t.p,{children:["Unlike Approach #2, you will not explicitly say which ",(0,s.jsx)(t.code,{children:"@rule"})," you want to run. Instead, look at the return type of your ",(0,s.jsx)(t.code,{children:"@rule"}),". Use ",(0,s.jsx)(t.code,{children:"rule_runner.request(MyOutput, [input1, ...])"}),", where ",(0,s.jsx)(t.code,{children:"MyOutput"})," is the return type."]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.code,{children:"rule_runner.request()"})," is equivalent to how you would normally use ",(0,s.jsx)(t.code,{children:"await Get(MyOuput, Input1, input1_instance)"})," in a rule (See ",(0,s.jsx)(t.a,{href:"/2.28/docs/writing-plugins/the-rules-api/concepts",children:"Concepts"}),"). For example, if you would normally say ",(0,s.jsx)(t.code,{children:"await Get(Digest, MergeDigests([digest1, digest2])"}),", you'd instead say ",(0,s.jsx)(t.code,{children:"rule_runner.request(Digest, [MergeDigests([digest1, digest2])"}),"."]}),"\n",(0,s.jsxs)(t.p,{children:["You will also need to add a ",(0,s.jsx)(t.code,{children:"QueryRule"})," to your ",(0,s.jsx)(t.code,{children:"RuleRunner"})," setup, which gives a hint to the engine for what requests you are going to make. The ",(0,s.jsx)(t.code,{children:"QueryRule"})," takes the same form as your ",(0,s.jsx)(t.code,{children:"rule_runner.request()"}),", except that the inputs are types, rather than instances of those types."]}),"\n",(0,s.jsx)(t.p,{children:"For example, given this rule signature (from the above Approach #2 example):"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:"@rule\nasync def find_needle_in_haystack(find_needle: FindNeedle) -> TargetsWithNeedle:\n    ...\n"})}),"\n",(0,s.jsx)(t.p,{children:"We could write this test:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'from pants.core.target_types import FileTarget\nfrom pants.testutil.rule_runner import QueryRule, RuleRunner\n\n@pytest.fixture\ndef rule_runner() -> RuleRunner:\n    return RuleRunner(\n        rules=[\n            find_needle_in_haystack,\n            QueryRule(TargetsWithNeedle, [FindNeedle]),\n        ],\n        target_types=[FileTarget],\n    )\n\n\ndef test_find_needle(rule_runner: RuleRunner) -> None:\n    # Set up the files and targets.\n    rule_runner.write_files(\n        {\n            "project/f1.txt": "",\n            "project/f2.txt": "",\n            "project/needle.txt": "",\n            "project/BUILD": dedent(\n                """\\\n                file(name="t1", source="f1.txt")\n                file(name="t2", source="f2.txt")\n                file(name="t3", source="needle.txt")\n                """\n            ),\n        }\n    )\n    tgt1 = rule_runner.get_target(Address("project", target_name="t1"))\n    tgt2 = rule_runner.get_target(Address("project", target_name="t2"))\n    tgt3 = rule_runner.get_target(Address("project", target_name="t3"))\n\n    # Run our rule.\n    find_needle_request = FindNeedle((tgt1, tgt2, tgt3), needle="needle.txt")\n    result = rule_runner.request(TargetsWithNeedle, [find_needle_request])\n    assert list(result) == [tgt3]\n'})}),"\n",(0,s.jsx)(t.p,{children:"Given this rule signature for running the linter Bandit:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:"@rule\nasync def bandit_lint(\n    request: BanditRequest, bandit: Bandit, python_setup: PythonSetup\n) -> LintResults:\n    ...\n"})}),"\n",(0,s.jsx)(t.p,{children:"We can write a test like this:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:"from pants.core.goals.lint import LintResult, LintResults\nfrom pants.testutil.rule_runner import QueryRule, RuleRunner\n\n@pytest.fixture\ndef rule_runner() -> RuleRunner:\n    return RuleRunner(\n        rules=[\n            *bandit_rules(),\n            QueryRule(LintResults, [BanditRequest]),\n        ],\n        target_types=[PythonSourceTarget]\n    )\n\ndef test_bandit(rule_runner: RuleRunner) -> None:\n    # Set up files and targets.\n    rule_runner.write_files(...)\n    ...\n\n    # Run Bandit rule.\n    bandit_request = BanditRequest(...)\n    lint_results = rule_runner.request(LintResults, [bandit_request])\n"})}),"\n",(0,s.jsxs)(t.p,{children:["Note that our ",(0,s.jsx)(t.code,{children:"@rule"})," takes 3 parameters, but we only explicitly included ",(0,s.jsx)(t.code,{children:"BanditRequest"})," in the inputs. This is possible because the engine knows how to compute all ",(0,s.jsx)(t.a,{href:"/2.28/docs/writing-plugins/the-rules-api/options-and-subsystems",children:"Subsystems"})," based on the initial input to the graph. See ",(0,s.jsx)(t.a,{href:"/2.28/docs/writing-plugins/the-rules-api/concepts",children:"Concepts"}),"."]}),"\n",(0,s.jsxs)(t.p,{children:["We are happy ",(0,s.jsx)(t.a,{href:"/community/members",children:"to help"})," figure out what rules to register, and what inputs to pass to ",(0,s.jsx)(t.code,{children:"rule_runner.request()"}),". It can also help to ",(0,s.jsx)(t.a,{href:"/2.28/docs/writing-plugins/the-rules-api/tips-and-debugging",children:"visualize the rule graph"})," when running your code in production. If you're missing an input that you need, the engine will error explaining that there is no way to compute your ",(0,s.jsx)(t.code,{children:"OutputType"}),"."]}),"\n",(0,s.jsxs)(t.h3,{id:"testing-goal_rules",children:["Testing ",(0,s.jsx)(t.code,{children:"@goal_rule"}),"s"]}),"\n",(0,s.jsxs)(t.p,{children:["You can run ",(0,s.jsx)(t.code,{children:"@goal_rule"}),"s by using ",(0,s.jsx)(t.code,{children:"rule_runner.run_goal_rule()"}),". The first argument is your ",(0,s.jsx)(t.code,{children:"Goal"})," subclass, such as ",(0,s.jsx)(t.code,{children:"Filedeps"})," or ",(0,s.jsx)(t.code,{children:"Lint"}),". Usually, you will set ",(0,s.jsx)(t.code,{children:"args: Iterable[str]"})," by giving the specs for the targets/files you want to run on, and sometimes passing options for your goal like ",(0,s.jsx)(t.code,{children:"--transitive"}),". If you need to also set global options that do not apply to your specific goal, set ",(0,s.jsx)(t.code,{children:"global_args: Iterable[str]"}),"."]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.code,{children:"run_goal_rule()"})," will return a ",(0,s.jsx)(t.code,{children:"GoalRuleResult"})," object, which has the fields ",(0,s.jsx)(t.code,{children:"exit_code: int"}),", ",(0,s.jsx)(t.code,{children:"stdout: str"}),", and ",(0,s.jsx)(t.code,{children:"stderr: str"}),"."]}),"\n",(0,s.jsxs)(t.p,{children:["For example, to test the ",(0,s.jsx)(t.code,{children:"filedeps"})," goal:"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'import pytest\n\nfrom pants.backend.project_info import filedeps\nfrom pants.backend.project_info.filedeps import Filedeps\nfrom pants.engine.target import Dependencies, SingleSourceField, Target\nfrom pants.testutil.rule_runner import RuleRunner\n\n# We create a mock `Target` for better isolation of our tests. We could have\n# instead used a pre-defined target like `PythonLibrary` or `Files`.\nclass MockTarget(Target):\n    alias = "tgt"\n    core_fields = (SingleSourceField, Dependencies)\n\n\n@pytest.fixture\ndef rule_runner() -> RuleRunner:\n    return RuleRunner(rules=filedeps.rules(), target_types=[MockTarget])\n\n\ndef test_one_target_one_source(rule_runner: RuleRunner) -> None:\n    rule_runner.write_files(\n        {\n            "project/example.ext": "",\n            "project/BUILD": "mock_tgt(source=\'example.ext\')"\n       }\n    )\n    result = rule_runner.run_goal_rule(Filedeps, args=["project/example.ext"])\n    assert result.stdout.splitlines() == ["project/BUILD", "project/example.ext"]\n'})}),"\n",(0,s.jsxs)(t.p,{children:["Unlike when testing normal ",(0,s.jsx)(t.code,{children:"@rules"}),", you do not need to define a ",(0,s.jsx)(t.code,{children:"QueryRule"})," when using ",(0,s.jsx)(t.code,{children:"rule_runner.run_goal_rule()"}),". This is already set up for you. However, you do need to make sure that your ",(0,s.jsx)(t.code,{children:"@goal_rule"})," and all the rules it depends on are registered with the ",(0,s.jsx)(t.code,{children:"RuleRunner"})," instance."]}),"\n",(0,s.jsxs)(t.h2,{id:"approach-4-run_pants-integration-tests-for-pants",children:["Approach 4: ",(0,s.jsx)(t.code,{children:"run_pants()"})," (integration tests for Pants)"]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.code,{children:"pants_integration_test.py "})," provides functions that allow you to run a full Pants process as it would run on the command line. It's useful for acceptance testing and for testing things that are too difficult to test with Approach #3."]}),"\n",(0,s.jsx)(t.p,{children:"You will typically use three functions:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.code,{children:"setup_tmpdir()"}),", which is a ",(0,s.jsx)(t.a,{href:"https://book.pythontips.com/en/latest/context_managers.html",children:"context manager"})," that sets up temporary files in the build root to simulate a real project.","\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["It takes a single parameter ",(0,s.jsx)(t.code,{children:"files: Mapping[str, str]"}),", which is a dictionary of file paths to file content.","\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"All file paths will be prefixed by the temporary directory."}),"\n",(0,s.jsxs)(t.li,{children:["File content can include ",(0,s.jsx)(t.code,{children:"{tmpdir}"}),", which will get substituted with the actual temporary directory."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(t.li,{children:"It yields the temporary directory, relative to the test's current work directory."}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.code,{children:"run_pants()"}),", which runs Pants using the ",(0,s.jsx)(t.code,{children:"list[str]"})," of arguments you pass, such as ",(0,s.jsx)(t.code,{children:'["help"]'}),".","\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsxs)(t.li,{children:["It returns a ",(0,s.jsx)(t.code,{children:"PantsResult"})," object, which has the fields ",(0,s.jsx)(t.code,{children:"exit_code: int"}),", ",(0,s.jsx)(t.code,{children:"stdout: str"}),", and ",(0,s.jsx)(t.code,{children:"stderr: str"}),"."]}),"\n",(0,s.jsxs)(t.li,{children:["It accepts several other optional arguments, including ",(0,s.jsx)(t.code,{children:"config"}),", ",(0,s.jsx)(t.code,{children:"extra_env"}),", and any keyword argument accepted by ",(0,s.jsx)(t.code,{children:"subprocess.Popen()"}),"."]}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.code,{children:"PantsResult.assert_success()"})," or ",(0,s.jsx)(t.code,{children:"PantsResult.assert_failure()"}),", which checks the exit code and prints a nice error message if unexpected."]}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"For example:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'from pants.testutil.pants_integration_test import run_pants, setup_tmpdir\n\ndef test_build_ignore_dependency() -> None:\n    sources = {\n        "dir1/BUILD": "files(sources=[])",\n        "dir2/BUILD": "files(sources=[], dependencies=[\'{tmpdir}/dir1\'])",\n    }\n    with setup_tmpdir(sources) as tmpdir:\n        ignore_result = run_pants(\n            [f"--build-ignore={tmpdir}/dir1", "dependencies", f"{tmpdir}/dir2"]\n        )\n        no_ignore_result = run_pants(["dependencies", f"{tmpdir}/dir2"])\n    ignore_result.assert_failure()\n    assert f"{tmpdir}/dir1" not in ignore_result.stderr\n    no_ignore_result.assert_success()\n    assert f"{tmpdir}/dir1" in no_ignore_result.stdout\n\n'})}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.code,{children:"run_pants()"})," is hermetic by default, meaning that it will not read your ",(0,s.jsx)(t.code,{children:"pants.toml"}),". As a result, you often need to include the option ",(0,s.jsx)(t.code,{children:"--backend-packages"})," in the arguments to ",(0,s.jsx)(t.code,{children:"run_pants()"}),". You can alternatively set the argument ",(0,s.jsx)(t.code,{children:"hermetic=False"}),", although we discourage this."]}),"\n",(0,s.jsx)(t.p,{children:"For example:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'from pants.testutil.pants_integration_test import run_pants, setup_tmpdir\n\n\ndef test_getting_list_of_files_from_a_target() -> None:\n    sources = {\n        "dir/BUILD": "files(sources=[\'subdir/*.txt\'])",\n        "dir/subdir/file1.txt": "",\n        "dir/subdir/file2.txt": "",\n    }\n    with setup_tmpdir(sources) as tmpdir:\n        result = run_pants(\n            [\n                "--backend-packages=[\'pants.backend.python\']",\n                "filedeps",\n                f"{tmpdir}/dir:",\n            ],\n        )\n    result.assert_success()\n    assert all(\n        filepath in result.stdout\n        for filepath in (\n            f"{tmpdir}/dir/subdir/file1.txt",\n            f"{tmpdir}/dir/subdir/file2.txt",\n        )\n    )\n'})}),"\n",(0,s.jsxs)(t.p,{children:["To read any files that were created, use ",(0,s.jsx)(t.code,{children:"get_buildroot()"})," as the first part of the path to ensure that the correct directory is read."]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'from pathlib import Path\n\nfrom pants.base.build_environment import get_buildroot\nfrom pants.testutil.pants_integration_test import run_pants, setup_tmpdir\n\ndef test_junit_report() -> None:\n    with setup_tmpdir(...) as tmpdir:\n        run_pants(["--coverage-py-reports=[\'json\']", "test", ...]).assert_success()\n    coverage_report = Path(get_buildroot(), "dist", "coverage", "python", "report.json")\n    assert coverage_report.read_text() == "foo"\n'})}),"\n",(0,s.jsx)(t.h3,{id:"debugging-integration-tests",children:"Debugging integration tests"}),"\n",(0,s.jsx)(t.p,{children:"While developing and debugging integration tests, you can have Pants stream the output for the Pants invocation under test to the console. This is useful, for example, when debugging long-running integration tests which would otherwise show no output while they run."}),"\n",(0,s.jsxs)(t.p,{children:["To use, adjust specific test(s) to use the ",(0,s.jsx)(t.code,{children:"stream_output"})," parameter, for example, ",(0,s.jsx)(t.code,{children:"run_pants_with_workdir(..., stream_output=True)"})," or ",(0,s.jsx)(t.code,{children:"run_pants(..., stream_output=True)"}),", and then run the test with ",(0,s.jsx)(t.code,{children:"pants test --debug path/to:test -- --capture=no"})," so the test is invoked as an interactive process and pytest does not capture the output during the run."]})]})}function c(e={}){let{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(d,{...e})}):d(e)}},848193(e,t,n){n.d(t,{R:()=>o,x:()=>l});var r=n(830758);let s={},i=r.createContext(s);function o(e){let t=r.useContext(i);return r.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function l(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:o(e.components),r.createElement(i.Provider,{value:t},e.children)}},791563(e){e.exports=JSON.parse('{"id":"docs/writing-plugins/the-rules-api/testing-plugins","title":"Testing plugins","description":"How to verify your plugin works.","source":"@site/versioned_docs/version-2.28/docs/writing-plugins/the-rules-api/testing-plugins.mdx","sourceDirName":"docs/writing-plugins/the-rules-api","slug":"/docs/writing-plugins/the-rules-api/testing-plugins","permalink":"/2.28/docs/writing-plugins/the-rules-api/testing-plugins","draft":false,"unlisted":false,"editUrl":"https://github.com/pantsbuild/pants/edit/main/docs/docs/writing-plugins/the-rules-api/testing-plugins.mdx","tags":[],"version":"2.28","sidebarPosition":9,"frontMatter":{"title":"Testing plugins","sidebar_position":9},"sidebar":"docsSidebar","previous":{"title":"Logging and dynamic output","permalink":"/2.28/docs/writing-plugins/the-rules-api/logging-and-dynamic-output"},"next":{"title":"Tips and debugging","permalink":"/2.28/docs/writing-plugins/the-rules-api/tips-and-debugging"}}')}}]);