"use strict";(self.webpackChunkpantsbuild_org=self.webpackChunkpantsbuild_org||[]).push([["597358"],{851082(e,t,s){s.r(t),s.d(t,{assets:()=>a,contentTitle:()=>o,default:()=>u,frontMatter:()=>l,metadata:()=>n,toc:()=>c});var n=s(372784),i=s(886070),r=s(848193);let l={title:"Run tests",sidebar_position:6},o,a={},c=[{value:"Automatic retries for tests",id:"automatic-retries-for-tests",level:2}];function d(e){let t={a:"a",admonition:"admonition",code:"code",h2:"h2",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsxs)(t.p,{children:["How to add a new test runner to the ",(0,i.jsx)(t.code,{children:"test"})," goal."]}),"\n",(0,i.jsx)(t.hr,{}),"\n",(0,i.jsxs)(t.ol,{children:["\n",(0,i.jsx)(t.li,{children:"Set up a test target type"}),"\n"]}),"\n",(0,i.jsx)(t.hr,{}),"\n",(0,i.jsxs)(t.p,{children:['Usually, you will want to add a "test" target type for your language, such as ',(0,i.jsx)(t.code,{children:"shell_test"})," or ",(0,i.jsx)(t.code,{children:"python_test"}),'. A test target contrasts with a "source" target, such as ',(0,i.jsx)(t.code,{children:"shell_source"}),". A test target is useful so that ",(0,i.jsx)(t.code,{children:"pants test ::"})," doesn't try to run tests on non-test files."]}),"\n",(0,i.jsxs)(t.p,{children:["When creating a test target, you should usually subclass ",(0,i.jsx)(t.code,{children:"SingleSourceField"}),". You may also want to create ",(0,i.jsx)(t.code,{children:"TimeoutField"})," (which should subclass ",(0,i.jsx)(t.code,{children:"IntField"}),") and a ",(0,i.jsx)(t.code,{children:"SkipField"})," (which should subclass ",(0,i.jsx)(t.code,{children:"BoolField"}),")."]}),"\n",(0,i.jsxs)(t.p,{children:["See ",(0,i.jsx)(t.a,{href:"/2.24/docs/writing-plugins/the-target-api/creating-new-targets",children:"Creating new targets"})," for a guide on how to define new target types."]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'from pants.engine.target import (\n    COMMON_TARGET_FIELDS,\n    Dependencies,\n    BoolField,\n    IntField,\n    SingleSourceField,\n    Target,\n)\n\n\nclass ExampleTestSourceField(SingleSourceField):\n    expected_file_extensions = (".example",)\n\n\nclass ExampleTestTimeoutField(IntField):\n     alias = "timeout"\n     help = "Whether to time out after a certain period of time"\n\n\nclass SkipExampleTestsField(BoolField):\n    alias = "skip_example_tests"\n    default = False\n    help = "If set, don\'t run tests on this source"\n\n\nclass ExampleTestTarget(Target):\n    alias = "example_tests"\n    help = "Example tests run by some tool"\n    core_fields = (\n        *COMMON_TARGET_FIELDS,\n        Dependencies,\n        ExampleTestSourceField,\n        ExampleTestTimeoutField,\n        SkipExampleTestsField,\n    )\n'})}),"\n",(0,i.jsxs)(t.ol,{start:"2",children:["\n",(0,i.jsxs)(t.li,{children:["Set up a subclass of ",(0,i.jsx)(t.code,{children:"TestFieldSet"})]}),"\n"]}),"\n",(0,i.jsx)(t.hr,{}),"\n",(0,i.jsxs)(t.p,{children:["Your test-runner will need access to some / most of the fields defined on your new target to actually execute the tests within. Collect those fields into a new subclass of ",(0,i.jsx)(t.code,{children:"TestFieldSet"}),", and mark at least your source field as required."]}),"\n",(0,i.jsxs)(t.p,{children:['If you have a "skip" field, use it in an ',(0,i.jsx)(t.code,{children:"opt_out"})," method of your subclass:"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"from pants.core.goals.test import TestFieldSet\n\n@dataclass(frozen=True)\nclass ExampleTestFieldSet(TestFieldSet):\n    required_fields = (ExamleTestSourceField,)\n    sources: ExampleTestSourceField\n    timeout: ExampleTestTimeoutField\n\n    @classmethod\n    def opt_out(cls, tgt: Target) -> bool:\n        return tgt.get(SkipExampleTestsField).value\n"})}),"\n",(0,i.jsxs)(t.ol,{start:"3",children:["\n",(0,i.jsxs)(t.li,{children:["Set up a ",(0,i.jsx)(t.code,{children:"Subsystem"})," for your test runner"]}),"\n"]}),"\n",(0,i.jsx)(t.hr,{}),"\n",(0,i.jsxs)(t.p,{children:["Test runners are expected to implement (at least) a ",(0,i.jsx)(t.code,{children:"skip"})," option at a subsystem level."]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:'from pants.option.option_types import SkipOption\nfrom pants.option.subsystem import Subsystem\n\nclass ExampleTestSubsystem(Subsystem):\n    name = "Example"\n    options_scope = "example-test"\n    help = "Some tool to run tests"\n\n    skip = SkipOption("test")\n'})}),"\n",(0,i.jsxs)(t.p,{children:["See ",(0,i.jsx)(t.a,{href:"/2.24/docs/writing-plugins/the-rules-api/options-and-subsystems",children:"Options and subsystems"})," for more information about defining new subsystems."]}),"\n",(0,i.jsxs)(t.ol,{start:"4",children:["\n",(0,i.jsxs)(t.li,{children:["Set up a subclass of ",(0,i.jsx)(t.code,{children:"TestRequest"})]}),"\n"]}),"\n",(0,i.jsx)(t.hr,{}),"\n",(0,i.jsxs)(t.p,{children:["The rules used to drive batching and executing tests come from the ",(0,i.jsx)(t.code,{children:"TestRequest"})," class. To use it, first declare a new subclass pointing at your subclasses of ",(0,i.jsx)(t.code,{children:"TestFieldSet"})," and ",(0,i.jsx)(t.code,{children:"Subsystem"}),":"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"from pants.core.goals.test import TestRequest\n\n@dataclass(frozen=True)\nclass ExampleTestRequest(TestRequest):\n    field_set_type = ExampleTestFieldSet\n    tool_subsystem = ExampleTestSubsystem\n"})}),"\n",(0,i.jsx)(t.p,{children:"Then register the rules of your subclass:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"def rules():\n    return [\n        # Add to any other existing rules here:\n        *ExampleTestRequest.rules()\n    ]\n"})}),"\n",(0,i.jsxs)(t.p,{children:["In addition to registering your subclass as a valid ",(0,i.jsx)(t.code,{children:"TestRequest"}),", this will automatically register rules to handle splitting your test inputs into single-element batches. If this is the correct behavior for your test runner, you can move on and skip the following section about defining a batching/partitioning rule. On the other hand, if your test runner supports testing multiple files in a single process (i.e. to share expensive setup logic), you can override the default ",(0,i.jsx)(t.code,{children:"partitioner_type"})," on your ",(0,i.jsx)(t.code,{children:"TestRequest"})," subclass:"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"from pants.core.goals.test import PartitionerType\n\n@dataclass(frozen=True)\nclass ExampleTestRequest(TestRequest):\n    field_set_type = ExampleTestFieldSet\n    tool_subsystem = ExampleTestSubsystem\n    # Changed from the default:\n    partitioner_type = PartitionerType.CUSTOM\n"})}),"\n",(0,i.jsx)(t.p,{children:'This will prevent generation of the "default" partitioning rule, allowing you to implement a custom rule for grouping compatible tests into the same process.'}),"\n",(0,i.jsxs)(t.ol,{start:"5",children:["\n",(0,i.jsxs)(t.li,{children:["Define a batching/partitioning ",(0,i.jsx)(t.code,{children:"@rule"})]}),"\n"]}),"\n",(0,i.jsx)(t.hr,{}),"\n",(0,i.jsx)(t.admonition,{title:"This step is optional",type:"caution",children:(0,i.jsxs)(t.p,{children:["Defining a partitioning rule is only required if you overrode the ",(0,i.jsx)(t.code,{children:"partitioner_type"})," field in your ",(0,i.jsx)(t.code,{children:"TestRequest"})," subclass to be ",(0,i.jsx)(t.code,{children:"PartitionerType.CUSTOM"}),". Skip to the next section if your subclass is using the default ",(0,i.jsx)(t.code,{children:"partitioner_type"}),"."]})}),"\n",(0,i.jsxs)(t.p,{children:["Pants can run tests from multiple targets/files within the same process (for example, to share expensive setup/teardown logic across multiple files). Since it's not always safe/possible to batch test files together, each plugin defining a ",(0,i.jsx)(t.code,{children:"test"})," implementation is expected to define a ",(0,i.jsx)(t.code,{children:"@rule"})," for splitting field-sets into appropriate batches:"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"from pants.core.goals.test import Partitions\nfrom pants.engine.rules import collect_rules, rule\n\n@rule\nasync def partition(\n    request: ExampleTestRequest.PartitionRequest[ExampleTestFieldSet]\n) -> Partitions:\n    ...\n\ndef rules():\n    return [\n        # If it isn't already in the list:\n        *collect_rules(),\n    ]\n"})}),"\n",(0,i.jsxs)(t.p,{children:["The ",(0,i.jsx)(t.code,{children:"Partitions"})," type is a custom collection of ",(0,i.jsx)(t.code,{children:"Partition"})," objects, and a ",(0,i.jsx)(t.code,{children:"Partition"})," is a ",(0,i.jsx)(t.code,{children:"dataclass"})," containing:"]}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["A ",(0,i.jsx)(t.code,{children:"tuple[TestFieldSetSubclass, ...]"})," of partition ",(0,i.jsx)(t.code,{children:"elements"})]}),"\n",(0,i.jsxs)(t.li,{children:["An optional ",(0,i.jsx)(t.code,{children:"metadata"})," field"]}),"\n"]}),"\n",(0,i.jsx)(t.p,{children:"Partition metadata can be any type implementing:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"@property\ndef description(self) -> str:\n    ...\n"})}),"\n",(0,i.jsxs)(t.p,{children:["Any metadata returned by the partitioning rule will be passed back to your test runner as an input to the test execution rule, so it can be useful to declare a custom type modeling everything that's constant for a collection of ",(0,i.jsx)(t.code,{children:"TestFieldSet"})," inputs:"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"@dataclass(frozen=True)\nclass ExampleTestMetadata:\n    common_property: str\n    other_common_property: int | None\n"})}),"\n",(0,i.jsxs)(t.ol,{start:"6",children:["\n",(0,i.jsxs)(t.li,{children:["Define the main test execution ",(0,i.jsx)(t.code,{children:"@rule"})]}),"\n"]}),"\n",(0,i.jsx)(t.hr,{}),"\n",(0,i.jsx)(t.p,{children:"To actually execute your test runner, define a rule like:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"from pants.core.goals.test import TestResult\n\n@rule\nasync def run_example_tests(\n    batch: ExampleTestRequest.Batch[ExampleTestFieldSet, ExampleTestMetadata],\n    # Any other subsystems/inputs you need.\n) -> TestResult:\n    ...\n"})}),"\n",(0,i.jsxs)(t.p,{children:["If you didn't define a custom metadata type, you can use ",(0,i.jsx)(t.code,{children:"Any"})," as the second type argument to the ",(0,i.jsx)(t.code,{children:"Batch"})," type:"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"from pants.core.goals.test import TestResult\n\n@rule\nasync def run_example_tests(\n    batch: ExampleTestRequest.Batch[ExampleTestFieldSet, Any],\n    # Any other subsystems/inputs you need.\n) -> TestResult:\n    ...\n"})}),"\n",(0,i.jsxs)(t.p,{children:["The ",(0,i.jsx)(t.code,{children:"batch"})," input will have two properties:"]}),"\n",(0,i.jsxs)(t.ol,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"elements"})," contains all the field sets that should be tested by your runner"]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"metadata"})," contains any (optional) common data about the batch returned by your partitioning rule"]}),"\n"]}),"\n",(0,i.jsxs)(t.p,{children:["If you didn't override the ",(0,i.jsx)(t.code,{children:"partitioner_type"})," in your ",(0,i.jsx)(t.code,{children:"TestRequest"})," subclass, ",(0,i.jsx)(t.code,{children:"elements"})," will be a list of size 1 and ",(0,i.jsx)(t.code,{children:"metadata"})," will be ",(0,i.jsx)(t.code,{children:"None"}),". For convenience, you can use ",(0,i.jsx)(t.code,{children:"batch.single_element"})," in this case to get the single field set. The ",(0,i.jsx)(t.code,{children:"single_element"})," property will raise a ",(0,i.jsx)(t.code,{children:"TypeError"})," if used on a batch with more than one element."]}),"\n",(0,i.jsxs)(t.ol,{start:"7",children:["\n",(0,i.jsxs)(t.li,{children:["Define ",(0,i.jsx)(t.code,{children:"@rule"}),"s for debug testing"]}),"\n"]}),"\n",(0,i.jsx)(t.hr,{}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.code,{children:"pants test"})," exposes ",(0,i.jsx)(t.code,{children:"--debug"})," and ",(0,i.jsx)(t.code,{children:"--debug-adapter"})," options for interactive execution of tests. To hook into these execution modes, opt-in in your ",(0,i.jsx)(t.code,{children:"TestRequest"})," subclass and define one/both additional rules:"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"from pants.core.goals.test import TestDebugAdapterRequest, TestDebugRequest\nfrom pants.core.subsystems.debug_adapter import DebugAdapterSubsystem\n\n@dataclass(frozen=True)\nclass ExampleTestRequest(TestRequest):\n    ...  # Fields from earlier\n    supports_debug = True  # Supports --debug\n    supports_debug_adapter = True  # Supports --debug-adapter\n\n@rule\nasync def setup_example_debug_test(\n    batch: ExampleTestRequest.Batch[ExampleTestFieldSet, ExampleTestMetadata],\n) -> TestDebugRequest:\n    ...\n\n@rule\nasync def setup_example_debug_adapter_test(\n    batch: ExampleTestRequest.Batch[ExampleTestFieldSet, ExampleTestMetadata],\n    debug_adapter: DebugAdapterSubsystem,\n) -> TestDebugAdapterRequest:\n    ...\n"})}),"\n",(0,i.jsx)(t.h2,{id:"automatic-retries-for-tests",children:"Automatic retries for tests"}),"\n",(0,i.jsx)(t.p,{children:"Running the process without retries could look like this:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"result = await Get(FallibleProcessResult, Process, my_test_process)\n"})}),"\n",(0,i.jsx)(t.p,{children:"Simply wrap the process in types that request the retries:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"results = await Get(\n    ProcessResultWithRetries, ProcessWithRetries(my_test_process, retry_count)\n)\nlast_result = results.last\n"})})]})}function u(e={}){let{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},848193(e,t,s){s.d(t,{R:()=>l,x:()=>o});var n=s(830758);let i={},r=n.createContext(i);function l(e){let t=n.useContext(r);return n.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function o(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:l(e.components),n.createElement(r.Provider,{value:t},e.children)}},372784(e){e.exports=JSON.parse('{"id":"docs/writing-plugins/common-plugin-tasks/run-tests","title":"Run tests","description":"How to add a new test runner to the test goal.","source":"@site/versioned_docs/version-2.24/docs/writing-plugins/common-plugin-tasks/run-tests.mdx","sourceDirName":"docs/writing-plugins/common-plugin-tasks","slug":"/docs/writing-plugins/common-plugin-tasks/run-tests","permalink":"/2.24/docs/writing-plugins/common-plugin-tasks/run-tests","draft":false,"unlisted":false,"editUrl":"https://github.com/pantsbuild/pants/edit/main/docs/docs/writing-plugins/common-plugin-tasks/run-tests.mdx","tags":[],"version":"2.24","sidebarPosition":6,"frontMatter":{"title":"Run tests","sidebar_position":6},"sidebar":"docsSidebar","previous":{"title":"Add a REPL","permalink":"/2.24/docs/writing-plugins/common-plugin-tasks/add-a-repl"},"next":{"title":"Add lockfiles","permalink":"/2.24/docs/writing-plugins/common-plugin-tasks/plugin-lockfiles"}}')}}]);