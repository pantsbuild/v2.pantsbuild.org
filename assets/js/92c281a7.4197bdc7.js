"use strict";(self.webpackChunkpantsbuild_org=self.webpackChunkpantsbuild_org||[]).push([["627909"],{509091(e,t,s){s.r(t),s.d(t,{assets:()=>d,contentTitle:()=>c,default:()=>u,frontMatter:()=>a,metadata:()=>n,toc:()=>h});var n=s(47849),i=s(886070),r=s(848193),o=s(685008),l=s(637180);let a={title:"test",sidebar_position:7},c,d={},h=[{value:"Examples",id:"examples",level:2},{value:"Pytest version and plugins",id:"pytest-version-and-plugins",level:2},{value:"Controlling output",id:"controlling-output",level:2},{value:"Passing arguments to Pytest",id:"passing-arguments-to-pytest",level:2},{value:"Config files",id:"config-files",level:2},{value:"<code>conftest.py</code>",id:"conftestpy",level:2},{value:"Setting environment variables",id:"setting-environment-variables",level:2},{value:"Batching and parallelism",id:"batching-and-parallelism",level:2},{value:"Batching tests",id:"batching-tests",level:3},{value:"Parallelism via <code>pytest-xdist</code>",id:"parallelism-via-pytest-xdist",level:3},{value:"Force reruns with <code>--force</code>",id:"force-reruns-with---force",level:2},{value:"Debugging Tests",id:"debugging-tests",level:2},{value:"Timeouts",id:"timeouts",level:2},{value:"Test utilities and resources",id:"test-utilities-and-resources",level:2},{value:"Test utilities",id:"test-utilities",level:3},{value:"Assets",id:"assets",level:3},{value:"Testing your packaging pipeline",id:"testing-your-packaging-pipeline",level:2},{value:"Coverage",id:"coverage",level:2},{value:"JUnit XML results",id:"junit-xml-results",level:2},{value:"Customizing Pytest command line options per target",id:"customizing-pytest-command-line-options-per-target",level:2},{value:"Failures to collect tests",id:"failures-to-collect-tests",level:2}];function p(e){let t={a:"a",admonition:"admonition",blockquote:"blockquote",code:"code",em:"em",h2:"h2",h3:"h3",hr:"hr",li:"li",mdxAdmonitionTitle:"mdxAdmonitionTitle",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,r.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.p,{children:"Run tests with Pytest."}),"\n",(0,i.jsx)(t.hr,{}),"\n",(0,i.jsxs)(t.p,{children:["Pants uses the ",(0,i.jsx)(t.a,{href:"https://docs.pytest.org/en/latest/",children:"Pytest"})," test runner to run Python tests. You may write your tests in Pytest-style, unittest-style, or mix and match both."]}),"\n",(0,i.jsxs)(t.admonition,{title:"Benefit of Pants: runs each file in parallel",type:"tip",children:[(0,i.jsx)(t.p,{children:"Each file gets run as a separate process, which gives you fine-grained caching and better parallelism. Given enough cores, Pants will be able to run all your tests at the same time."}),(0,i.jsxs)(t.p,{children:["This also gives you fine-grained invalidation. If you run ",(0,i.jsx)(t.code,{children:"pants test ::"}),", and then you only change one file, then only tests that depended on that changed file will need to rerun."]})]}),"\n",(0,i.jsx)(t.h2,{id:"examples",children:"Examples"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-bash",children:" # Run all tests in the repository.\n\u276F pants test ::\n\n# Run all the tests in this directory.\n\u276F pants test helloworld/util:\n\n# Run just the tests in this file.\n\u276F pants test helloworld/util/lang_test.py\n\n # Run just one test.\n\u276F pants test helloworld/util/lang_test.py -- -k test_language_translator\n"})}),"\n",(0,i.jsx)(t.h2,{id:"pytest-version-and-plugins",children:"Pytest version and plugins"}),"\n",(0,i.jsxs)(t.p,{children:["To change the Pytest version, set the ",(0,i.jsx)(t.code,{children:"install_from_resolve"})," option in the ",(0,i.jsx)(t.code,{children:"[pytest]"})," scope. You may also add ",(0,i.jsx)(t.a,{href:"https://docs.pytest.org/en/latest/plugins.html",children:"plugins"})," including the plugins in the resolve:"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-toml",metastring:'title="pants.toml"',children:'[python.resolves]\npytest = "3rdparty/python/pytest-lock.txt"\n\n[pytest]\ninstall_from_resolve = "pytest"\n'})}),"\n",(0,i.jsxs)(t.p,{children:["Then, add a ",(0,i.jsx)(t.code,{children:"requirements.txt"})," file specifying the version of ",(0,i.jsx)(t.code,{children:"pytest"})," and other plugins:"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-text",metastring:'title="pytest-requirements.txt"',children:"pytest>=5.4\npytest-django>=3.9.0,<4\npytest-rerunfailures==9.0\n"})}),"\n",(0,i.jsxs)(t.p,{children:["Finally, generate the relevant lockfile with ",(0,i.jsx)(t.code,{children:"pants generate-lockfiles --resolve=pytest"}),". For more information, see ",(0,i.jsx)(t.a,{href:"/2.18/docs/python/overview/lockfiles#lockfiles-for-tools",children:"Lockfiles for tools"}),"."]}),"\n",(0,i.jsxs)(t.p,{children:["Alternatively, if you only want to install the plugin for certain tests, you can add the plugin to the ",(0,i.jsx)(t.code,{children:"dependencies"})," field of your ",(0,i.jsx)(t.code,{children:"python_test"})," / ",(0,i.jsx)(t.code,{children:"python_tests"})," target. See ",(0,i.jsx)(t.a,{href:"/2.18/docs/python/overview/third-party-dependencies",children:"Third-party dependencies"})," for how to install Python dependencies. For example:"]}),"\n",(0,i.jsxs)(o.A,{groupId:"code-examples",children:[(0,i.jsx)(l.A,{value:"requirements.txt",label:"requirements.txt",children:(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-text",metastring:'tab={"label":"requirements.txt"}',children:"pytest-django==3.10.0\n"})})}),(0,i.jsx)(l.A,{value:"build",label:"BUILD",children:(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",metastring:'tab={"label":"BUILD"}',children:'python_requirements(name="reqs")\n'})})}),(0,i.jsx)(l.A,{value:"helloworld/util/build",label:"helloworld/util/BUILD",children:(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",metastring:'tab={"label":"helloworld/util/BUILD"}',children:'python_tests(\n   name="tests",\n   # Normally, Pants infers dependencies based on imports.\n   # Here, we don\'t actually import our plugin, though, so\n   # we need to explicitly list it.\n   dependencies=["//:reqs#pytest-django"],\n)\n'})})})]}),"\n",(0,i.jsx)(t.h2,{id:"controlling-output",children:"Controlling output"}),"\n",(0,i.jsxs)(t.p,{children:["By default, Pants only shows output for failed tests. You can change this by setting ",(0,i.jsx)(t.code,{children:"--test-output"})," to one of ",(0,i.jsx)(t.code,{children:"all"}),", ",(0,i.jsx)(t.code,{children:"failed"}),", or ",(0,i.jsx)(t.code,{children:"never"}),", e.g. ",(0,i.jsx)(t.code,{children:"pants test --output=all ::"}),"."]}),"\n",(0,i.jsxs)(t.p,{children:["You can permanently set the output format in your ",(0,i.jsx)(t.code,{children:"pants.toml"})," like this:"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-toml",metastring:'title="pants.toml"',children:'[test]\noutput = "all"\n'})}),"\n",(0,i.jsxs)(t.admonition,{title:"Tip: Use Pytest options to make output more or less verbose",type:"note",children:[(0,i.jsxs)(t.p,{children:["See ",(0,i.jsx)(t.a,{href:"/2.18/docs/python/goals/test#passing-arguments-to-pytest",children:'"Passing arguments to Pytest"'}),"."]}),(0,i.jsx)(t.p,{children:"For example:"}),(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-bash",children:"\u276F pants test project/app_test.py -- -q\n"})}),(0,i.jsxs)(t.p,{children:["You may want to permanently set the Pytest option ",(0,i.jsx)(t.code,{children:"--no-header"})," to avoid printing the Pytest version for each test run:"]}),(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-toml",children:'[pytest]\nargs = ["--no-header"]\n'})})]}),"\n",(0,i.jsx)(t.h2,{id:"passing-arguments-to-pytest",children:"Passing arguments to Pytest"}),"\n",(0,i.jsxs)(t.p,{children:["To pass arguments to Pytest, put them at the end after ",(0,i.jsx)(t.code,{children:"--"}),", like this:"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-bash",children:"\u276F pants test project/app_test.py -- -k test_function1 -vv -s\n"})}),"\n",(0,i.jsxs)(t.p,{children:["You can also use the ",(0,i.jsx)(t.code,{children:"args"})," option in the ",(0,i.jsx)(t.code,{children:"[pytest]"})," scope, like this:"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-toml",metastring:'title="pants.toml"',children:'[pytest]\nargs = ["-vv"]\n'})}),"\n",(0,i.jsxs)(t.admonition,{title:"Tip: some useful Pytest arguments",type:"note",children:[(0,i.jsxs)(t.p,{children:["See ",(0,i.jsx)(t.a,{href:"https://docs.pytest.org/en/latest/usage.html",children:"https://docs.pytest.org/en/latest/usage.html"})," for more information."]}),(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"-k expression"}),": only run tests matching the expression."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"-v"}),": verbose mode."]}),"\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"-s"}),": always print the stdout and stderr of your code, even if a test passes."]}),"\n"]})]}),"\n",(0,i.jsxs)(t.admonition,{type:"caution",children:[(0,i.jsxs)(t.mdxAdmonitionTitle,{children:["How to use Pytest's ",(0,i.jsx)(t.code,{children:"--pdb"})," option"]}),(0,i.jsxs)(t.p,{children:["You must run ",(0,i.jsx)(t.code,{children:"pants test --debug"}),' for this to work properly. See the section "Debugging Tests" for more information.']})]}),"\n",(0,i.jsx)(t.h2,{id:"config-files",children:"Config files"}),"\n",(0,i.jsxs)(t.p,{children:["Pants will automatically include any relevant config files in the process's sandbox: ",(0,i.jsx)(t.code,{children:"pytest.ini"}),", ",(0,i.jsx)(t.code,{children:"pyproject.toml"}),", ",(0,i.jsx)(t.code,{children:"tox.ini"}),", and ",(0,i.jsx)(t.code,{children:"setup.cfg"}),"."]}),"\n",(0,i.jsx)(t.h2,{id:"conftestpy",children:(0,i.jsx)(t.code,{children:"conftest.py"})}),"\n",(0,i.jsxs)(t.p,{children:["Pytest uses ",(0,i.jsxs)(t.a,{href:"https://docs.pytest.org/en/stable/fixture.html#conftest-py-sharing-fixture-functions",children:[(0,i.jsx)(t.code,{children:"conftest.py"})," files"]})," to share fixtures and config across multiple distinct test files."]}),"\n",(0,i.jsxs)(t.p,{children:["The default ",(0,i.jsx)(t.code,{children:"sources"})," value for the ",(0,i.jsx)(t.code,{children:"python_test_utils"})," target includes ",(0,i.jsx)(t.code,{children:"conftest.py"}),". You can run ",(0,i.jsx)(t.a,{href:"/2.18/docs/getting-started/initial-configuration#5-generate-build-files",children:(0,i.jsx)(t.code,{children:"pants tailor ::"})})," to automatically add this target:"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{children:"pants tailor ::\nCreated project/BUILD:\n  - Add python_sources target project\n  - Add python_tests target tests\n  - Add python_test_utils target test_utils\n"})}),"\n",(0,i.jsxs)(t.p,{children:["Pants will also infer dependencies on any ",(0,i.jsx)(t.code,{children:"confest.py"})," files in the current directory ",(0,i.jsx)(t.em,{children:"and"})," any ancestor directories, which mirrors how Pytest behaves. This requires that each ",(0,i.jsx)(t.code,{children:"conftest.py"})," has a target referring to it. You can verify this is working correctly by running ",(0,i.jsx)(t.code,{children:"pants dependencies path/to/my_test.py"})," and confirming that each ",(0,i.jsx)(t.code,{children:"conftest.py"})," file shows up. (You can turn off this feature by setting ",(0,i.jsx)(t.code,{children:"conftests = false"})," in the ",(0,i.jsx)(t.code,{children:"[python-infer]"})," scope.)"]}),"\n",(0,i.jsx)(t.h2,{id:"setting-environment-variables",children:"Setting environment variables"}),"\n",(0,i.jsxs)(t.p,{children:["Test runs are ",(0,i.jsx)(t.em,{children:"hermetic"}),", meaning that they are stripped of the parent ",(0,i.jsx)(t.code,{children:"pants"})," process's environment variables. This is important for reproducibility, and it also increases cache hits."]}),"\n",(0,i.jsxs)(t.p,{children:["To add any arbitrary environment variable back to the process, you can either add the environment variable to the specific tests with the ",(0,i.jsx)(t.code,{children:"extra_env_vars"})," field on ",(0,i.jsx)(t.code,{children:"python_test"})," / ",(0,i.jsx)(t.code,{children:"python_tests"})," targets or to all your tests with the ",(0,i.jsx)(t.code,{children:"[test].extra_env_vars"})," option. Generally, prefer the field ",(0,i.jsx)(t.code,{children:"extra_env_vars"})," field so that more of your tests are hermetic."]}),"\n",(0,i.jsxs)(t.p,{children:["With both ",(0,i.jsx)(t.code,{children:"[test].extra_env_vars"})," and the ",(0,i.jsx)(t.code,{children:"extra_env_vars"}),' field, you can either hardcode a value or leave off a value to "allowlist" it and read from the parent ',(0,i.jsx)(t.code,{children:"pants"})," process's environment."]}),"\n",(0,i.jsxs)(o.A,{groupId:"code-examples",children:[(0,i.jsx)(l.A,{value:"pants.toml",label:"pants.toml",children:(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-toml",metastring:'tab={"label":"pants.toml"}',children:'[test]\nextra_env_vars = ["VAR1", "VAR2=hardcoded_value"]\n'})})}),(0,i.jsx)(l.A,{value:"project/build",label:"project/BUILD",children:(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",metastring:'tab={"label":"project/BUILD"}',children:'python_tests(\n    name="tests",\n    # Adds to all generated `python_test` targets,\n    # i.e. each file in the `sources` field.\n    extra_env_vars=["VAR3", "VAR4=hardcoded"],\n    # Even better, use `overrides` to be more granular.\n    overrides={\n        "strutil_test.py": {"extra_env_vars": ["VAR"]},\n        ("dirutil_test.py", "osutil_test.py"): {"extra_env_vars": ["VAR5"]},\n    },\n)\n'})})})]}),"\n",(0,i.jsxs)(t.admonition,{type:"note",children:[(0,i.jsxs)(t.mdxAdmonitionTitle,{children:["Tip: avoiding collisions between concurrent ",(0,i.jsx)(t.code,{children:"pytest"})," runs using env vars"]}),(0,i.jsxs)(t.p,{children:["Sometimes your tests/code will need to reach outside of the sandbox, for example to initialize a test DB schema. In these cases you may see conflicts between concurrent ",(0,i.jsx)(t.code,{children:"pytest"})," processes scheduled by Pants, when two or more tests try to set up / tear down the same resource concurrently. To avoid this issue, you can set ",(0,i.jsx)(t.code,{children:"[pytest].execution_slot_var"})," to be a valid environment variable name. Pants will then inject a variable with that name into each ",(0,i.jsx)(t.code,{children:"pytest"})," run, using the process execution slot ID (an integer) as the variable's value. You can then update your test code to check for the presence of the variable and incorporate its value into generated DB names / file paths. For example, in a project using ",(0,i.jsx)(t.code,{children:"pytest-django"})," you could do:"]}),(0,i.jsxs)(o.A,{groupId:"code-examples",children:[(0,i.jsx)(l.A,{value:"pants.toml",label:"pants.toml",children:(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-toml",metastring:'tab={"label":"pants.toml"}',children:'[pytest]\nexecution_slot_var = "PANTS_EXECUTION_SLOT"\n'})})}),(0,i.jsx)(l.A,{value:"src/conftest.py",label:"src/conftest.py",children:(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",metastring:'tab={"label":"src/conftest.py"}',children:'from pytest_django.fixtures import _set_suffix_to_test_databases\nfrom pytest_django.lazy_django import skip_if_no_django\n\n@pytest.fixture(scope="session")\ndef django_db_modify_db_settings():\n    skip_if_no_django()\n    if "PANTS_EXECUTION_SLOT" in os.environ:\n        _set_suffix_to_test_databases(os.environ["PANTS_EXECUTION_SLOT"])\n'})})})]})]}),"\n",(0,i.jsx)(t.h2,{id:"batching-and-parallelism",children:"Batching and parallelism"}),"\n",(0,i.jsxs)(t.p,{children:["By default, Pants will schedule concurrent ",(0,i.jsx)(t.code,{children:"pytest"})," runs for each Python test file passed to the ",(0,i.jsx)(t.code,{children:"test"})," goal. This approach provides parallelism with fine-grained caching, but can have drawbacks in some situations:"]}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:[(0,i.jsx)(t.code,{children:"package"}),"- and ",(0,i.jsx)(t.code,{children:"session"}),"-scoped ",(0,i.jsx)(t.code,{children:"pytest"})," fixtures will execute once per ",(0,i.jsx)(t.code,{children:"python_test"})," target, instead of once per directory / once overall. This can cause significant overhead if you have many tests scoped under a time-intensive fixture (i.e. a fixture that sets up a large DB schema)."]}),"\n",(0,i.jsxs)(t.li,{children:["Tests ",(0,i.jsx)(t.em,{children:"within"})," a ",(0,i.jsx)(t.code,{children:"python_test"})," file will execute sequentially. This can be slow if you have large files containing many tests."]}),"\n"]}),"\n",(0,i.jsx)(t.h3,{id:"batching-tests",children:"Batching tests"}),"\n",(0,i.jsxs)(t.p,{children:["Running multiple test files within a single ",(0,i.jsx)(t.code,{children:"pytest"})," process can sometimes improve performance by allowing reuse of expensive high-level ",(0,i.jsx)(t.code,{children:"pytest"})," fixtures. Pants allows users to opt into this behavior via the ",(0,i.jsx)(t.code,{children:"batch_compatibility_tag"})," field on ",(0,i.jsx)(t.code,{children:"python_test"}),", with the following rules:"]}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:["If the field is not set, the ",(0,i.jsx)(t.code,{children:"python_test"})," is assumed to be incompatible with all others and will run in a dedicated ",(0,i.jsx)(t.code,{children:"pytest"})," process."]}),"\n",(0,i.jsxs)(t.li,{children:["If the field is set and is different from the value on some other ",(0,i.jsx)(t.code,{children:"python_test"}),", the tests are explicitly incompatible and are guaranteed to not run in the same ",(0,i.jsx)(t.code,{children:"pytest"})," process."]}),"\n",(0,i.jsxs)(t.li,{children:["If the field is set and is equal to the value on some other ",(0,i.jsx)(t.code,{children:"python_test"}),", the tests are explicitly compatible and ",(0,i.jsx)(t.em,{children:"may"})," run in the same ",(0,i.jsx)(t.code,{children:"pytest"})," process."]}),"\n"]}),"\n",(0,i.jsxs)(t.p,{children:["Compatible tests ",(0,i.jsx)(t.em,{children:"may not"})," end up in the same ",(0,i.jsx)(t.code,{children:"pytest"})," batch if:"]}),"\n",(0,i.jsxs)(t.ul,{children:["\n",(0,i.jsxs)(t.li,{children:['There are "too many" tests with the same ',(0,i.jsx)(t.code,{children:"batch_compatibility_tag"}),", as determined by the ",(0,i.jsx)(t.code,{children:"[test].batch_size"})," setting."]}),"\n",(0,i.jsxs)(t.li,{children:["Compatible tests have some incompatibility in Pants metadata (i.e. different ",(0,i.jsx)(t.code,{children:"resolve"})," or ",(0,i.jsx)(t.code,{children:"extra_env_vars"}),")."]}),"\n"]}),"\n",(0,i.jsxs)(t.p,{children:["Compatible tests that ",(0,i.jsx)(t.em,{children:"do"})," end up in the same batch will run in a single ",(0,i.jsx)(t.code,{children:"pytest"})," invocation. By default the tests will run sequentially, but they can be parallelized by enabling ",(0,i.jsx)(t.code,{children:"pytest-xdist"})," (see below). A single success/failure result will be reported for the entire batch, and additional output files (i.e. XML results and coverage) will encapsulate all of the included Python test files."]}),"\n",(0,i.jsxs)(t.admonition,{title:"Tip: finding failed tests in large batches",type:"note",children:[(0,i.jsxs)(t.p,{children:["It can sometimes be difficult to locate test failures in the logging output of a large ",(0,i.jsx)(t.code,{children:"pytest"})," batch. You can pass the ",(0,i.jsx)(t.code,{children:"-r"})," flag to ",(0,i.jsx)(t.code,{children:"pytest"})," to make this investigation easier:"]}),(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-bash",children:"\u276F pants test :: -- -r\n"})}),(0,i.jsxs)(t.p,{children:["This will cause ",(0,i.jsx)(t.code,{children:"pytest"}),' to print a "summary report" at the end of its output, including the names of all failed tests. See the ',(0,i.jsx)(t.code,{children:"pytest"})," docs ",(0,i.jsx)(t.a,{href:"https://docs.pytest.org/en/6.2.x/usage.html#detailed-summary-report",children:"here"})," for more information."]})]}),"\n",(0,i.jsxs)(t.p,{children:["The high-level ",(0,i.jsx)(t.code,{children:"pytest"})," fixtures that motivate batched testing are often defined in a ",(0,i.jsx)(t.code,{children:"conftest.py"})," near the root of your repository, applying to every test in a directory tree. In these cases, you can mark all the tests in the directory tree as compatible using the ",(0,i.jsxs)(t.a,{href:"/2.18/docs/using-pants/key-concepts/targets-and-build-files#field-default-values",children:[(0,i.jsx)(t.code,{children:"__defaults__"})," builtin"]}),":"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",metastring:'title="BUILD"',children:'python_test_utils()\n\n__defaults__({(python_test, python_tests): dict(batch_compatibility_tag="your-tag-here"),})\n'})}),"\n",(0,i.jsx)(t.admonition,{title:"Caching batched tests",type:"caution",children:(0,i.jsxs)(t.p,{children:["Batched test results are cached together by Pants, meaning that if any file in the batch changes (or if a file is added to / removed from the batch) then the entire batch will be invalidated and need to re-run. Depending on the time it takes to execute your fixtures and the number of tests sharing those fixtures, you may see better performance overall by setting a lower value for ",(0,i.jsx)(t.code,{children:"[test].batch_size"}),", improving your cache-hit rate to skip running tests more often."]})}),"\n",(0,i.jsxs)(t.h3,{id:"parallelism-via-pytest-xdist",children:["Parallelism via ",(0,i.jsx)(t.code,{children:"pytest-xdist"})]}),"\n",(0,i.jsxs)(t.p,{children:["Pants includes built-in support for ",(0,i.jsx)(t.code,{children:"pytest-xdist"}),", which can be enabled by setting:"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-toml",metastring:'title="pants.toml"',children:"[pytest]\nxdist_enabled = true\n"})}),"\n",(0,i.jsxs)(t.p,{children:["This will cause Pants to pass ",(0,i.jsx)(t.code,{children:"-n <concurrency>"})," when running ",(0,i.jsx)(t.code,{children:"pytest"}),". When this is set, ",(0,i.jsx)(t.code,{children:"pytest"})," will parallelize the tests ",(0,i.jsx)(t.em,{children:"within"})," your ",(0,i.jsx)(t.code,{children:"python_test"})," file, instead of running them sequentially. If multiple ",(0,i.jsx)(t.code,{children:"python_test"}),"s are batched into the same process, ",(0,i.jsx)(t.code,{children:"pytest-xdist"})," will parallelize the tests within ",(0,i.jsx)(t.em,{children:"all"})," of the files - this can help you regain the benefits of Pants' native concurrency when running batched tests."]}),"\n",(0,i.jsxs)(t.p,{children:["By default, Pants will automatically compute the value of ",(0,i.jsx)(t.code,{children:"<concurrency>"})," for each target based on the number of tests defined in the file and the number of available worker threads. You can instead set a hard-coded upper limit on the concurrency per target:"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",metastring:'title="BUILD"',children:'python_test(name="tests", source="tests.py", xdist_concurrency=4)\n'})}),"\n",(0,i.jsxs)(t.p,{children:["To explicitly disable the use of ",(0,i.jsx)(t.code,{children:"pytest-xdist"})," for a target, set ",(0,i.jsx)(t.code,{children:"xdist_concurrency=0"}),". This can be necessary for tests that are not safe to run in parallel."]}),"\n",(0,i.jsxs)(t.admonition,{title:"Parallelism in multiple concurrent processes",type:"caution",children:[(0,i.jsxs)(t.p,{children:["Pants will limit the total number of parallel tests running across ",(0,i.jsx)(t.em,{children:"all"})," scheduled processes so that it does not exceed the configured value of ",(0,i.jsx)(t.code,{children:"[GLOBAL].process_execution_local_parallelism"})," (by default, the number of CPUs available on the machine running Pants). For example, if your machine has 8 CPUs and Pants schedules 8 concurrent ",(0,i.jsx)(t.code,{children:"pytest"})," processes with ",(0,i.jsx)(t.code,{children:"pytest-xdist"})," enabled, it will pass ",(0,i.jsx)(t.code,{children:"-n 1"})," to each process so that the total concurrency is 8."]}),(0,i.jsxs)(t.p,{children:["It is possible to work around this behavior by marking all of your ",(0,i.jsx)(t.code,{children:"python_test"})," targets as batch-compatible and setting a very large value for ",(0,i.jsx)(t.code,{children:"[test].batch_size"}),". This will cause Pants to schedule fewer processes (containing more ",(0,i.jsx)(t.code,{children:"python_test"}),"s each) overall, allowing for larger values of ",(0,i.jsx)(t.code,{children:"-n <concurrency>"}),". Note however that this approach will limit the cacheability of your tests."]})]}),"\n",(0,i.jsxs)(t.p,{children:["When ",(0,i.jsx)(t.code,{children:"pytest-xdist"})," is in use, the ",(0,i.jsx)(t.code,{children:"PYTEST_XDIST_WORKER"})," and ",(0,i.jsx)(t.code,{children:"PYTEST_XDIST_WORKER_COUNT"})," environment variables will be automatically set. You can use those values (in addition to ",(0,i.jsx)(t.code,{children:"[pytest].execution_slot_var"}),") to avoid collisions between parallel tests (i.e. by using the combination of ",(0,i.jsx)(t.code,{children:"[pytest].execution_slot_var"})," and ",(0,i.jsx)(t.code,{children:"PYTEST_XDIST_WORKER"})," as a suffix for generated database names / file paths)."]}),"\n",(0,i.jsxs)(t.admonition,{type:"caution",children:[(0,i.jsxs)(t.mdxAdmonitionTitle,{children:[(0,i.jsx)(t.code,{children:"pytest-xdist"})," and high-level fixtures"]}),(0,i.jsxs)(t.p,{children:["Use of ",(0,i.jsx)(t.code,{children:"pytest-xdist"})," may cause high-level ",(0,i.jsx)(t.code,{children:"pytest"})," fixtures to execute more often than expected. See the ",(0,i.jsx)(t.code,{children:"pytest-xdist"})," docs ",(0,i.jsx)(t.a,{href:"https://pypi.org/project/pytest-xdist/#making-session-scoped-fixtures-execute-only-once",children:"here"})," for more details, and tips on how to mitigate this."]})]}),"\n",(0,i.jsxs)(t.h2,{id:"force-reruns-with---force",children:["Force reruns with ",(0,i.jsx)(t.code,{children:"--force"})]}),"\n",(0,i.jsxs)(t.p,{children:["To force your tests to run again, rather than reading from the cache, run ",(0,i.jsx)(t.code,{children:"pants test --force path/to/test.py"}),"."]}),"\n",(0,i.jsx)(t.h2,{id:"debugging-tests",children:"Debugging Tests"}),"\n",(0,i.jsx)(t.p,{children:"Because Pants runs multiple test targets in parallel, you will not see your test results appear on the screen until the test has completely finished. This means that you cannot use debuggers normally; the breakpoint will never show up on your screen and the test will hang indefinitely (or timeout, if timeouts are enabled)."}),"\n",(0,i.jsxs)(t.p,{children:["Instead, if you want to run a test interactively\u2014such as to use a debugger like ",(0,i.jsx)(t.code,{children:"pdb"}),"\u2014run your tests with ",(0,i.jsx)(t.code,{children:"pants test --debug"}),". For example:"]}),"\n",(0,i.jsxs)(o.A,{groupId:"code-examples",children:[(0,i.jsx)(l.A,{value:"test_debug_example.py",label:"test_debug_example.py",children:(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",metastring:'tab={"label":"test_debug_example.py"}',children:"def test_debug():\n    import pdb; pdb.set_trace()\n    assert 1 + 1 == 2\n"})})}),(0,i.jsx)(l.A,{value:"shell",label:"Shell",children:(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-text",metastring:'tab={"label":"Shell"}',children:"\u276F pants test --debug test_debug_example.py\n\n===================================================== test session starts =====================================================\nplatform darwin -- Python 3.6.10, pytest-5.3.5, py-1.8.1, pluggy-0.13.1\nrootdir: /private/var/folders/sx/pdpbqz4x5cscn9hhfpbsbqvm0000gn/T/.tmpn2li0z\nplugins: cov-2.8.1, timeout-1.3.4\ncollected 6 items\n\ntest_debug_example.py\n>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> PDB set_trace (IO-capturing turned off) >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n> /private/var/folders/sx/pdpbqz4x5cscn9hhfpbsbqvm0000gn/T/.tmpn2li0z/test_debug_example.py(11)test_debug()\n-> assert 1 + 1 == 2\n(Pdb) 1 + 1\n2\n"})})})]}),"\n",(0,i.jsxs)(t.p,{children:["If you use multiple files with ",(0,i.jsx)(t.code,{children:"test --debug"}),", they will run sequentially rather than in parallel."]}),"\n",(0,i.jsxs)(t.admonition,{type:"note",children:[(0,i.jsxs)(t.mdxAdmonitionTitle,{children:["Tip: using ",(0,i.jsx)(t.code,{children:"ipdb"})," in tests"]}),(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.a,{href:"https://github.com/gotcha/ipdb",children:(0,i.jsx)(t.code,{children:"ipdb"})})," integrates IPython with the normal ",(0,i.jsx)(t.code,{children:"pdb"})," debugger for enhanced features like autocomplete and improved syntax highlighting. ",(0,i.jsx)(t.code,{children:"ipdb"})," is very helpful when debugging tests."]}),(0,i.jsxs)(t.p,{children:["To be able to access ",(0,i.jsx)(t.code,{children:"ipdb"})," when running tests, add this to your ",(0,i.jsx)(t.code,{children:"pants.toml"}),":"]}),(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-toml",children:'[pytest]\nextra_requirements.add = ["ipdb"]\n'})}),(0,i.jsxs)(t.p,{children:["Then, you can use ",(0,i.jsx)(t.code,{children:"import ipdb; ipdb.set_trace()"})," in your tests."]}),(0,i.jsxs)(t.p,{children:["To run the tests you will need to add ",(0,i.jsx)(t.code,{children:"-- -s"})," to the test call since ipdb will need stdin and pytest will capture it."]}),(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-bash",children:"\u276F pants test --debug  <target>   -- -s\n"})})]}),"\n",(0,i.jsxs)(t.admonition,{type:"note",children:[(0,i.jsxs)(t.mdxAdmonitionTitle,{children:["Tip: using the VS Code (or any ",(0,i.jsx)(t.a,{href:"https://microsoft.github.io/debug-adapter-protocol/",children:"DAP"}),"-compliant editor) remote debugger in tests"]}),(0,i.jsxs)(t.ol,{children:["\n",(0,i.jsx)(t.li,{children:"In your editor, set your breakpoints and any other debug settings (like break-on-exception)."}),"\n",(0,i.jsxs)(t.li,{children:["Run your test with ",(0,i.jsx)(t.code,{children:"pants test --debug-adapter"}),"."]}),"\n",(0,i.jsxs)(t.li,{children:["Connect your editor to the server. The server host and port are logged by Pants when executing ",(0,i.jsx)(t.code,{children:"test --debug-adapter"}),". (They can also be configured using the ",(0,i.jsx)(t.code,{children:"[debug-adapter]"})," subsystem)."]}),"\n"]})]}),"\n",(0,i.jsxs)(t.blockquote,{children:["\n",(0,i.jsxs)(t.p,{children:["Run your test with ",(0,i.jsx)(t.code,{children:"pants test --debug"})," as usual."]}),"\n"]}),"\n",(0,i.jsxs)(t.admonition,{title:"Tip: using the IntelliJ/PyCharm remote debugger in tests",type:"note",children:[(0,i.jsxs)(t.p,{children:["First, add this to your ",(0,i.jsx)(t.code,{children:"pants.toml"}),":"]}),(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-toml",children:'[pytest]\nextra_requirements.add = ["pydevd-pycharm==203.5419.8"]  # Or whatever version you choose.\n'})}),(0,i.jsx)(t.p,{children:"Now, use the remote debugger as usual:"}),(0,i.jsxs)(t.ol,{children:["\n",(0,i.jsx)(t.li,{children:"Start a Python remote debugging session in PyCharm, say on port 5000."}),"\n",(0,i.jsx)(t.li,{children:"Add the following code at the point where you want execution to pause and connect to the debugger:"}),"\n"]}),(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",children:"import pydevd_pycharm\npydevd_pycharm.settrace('localhost', port=5000, stdoutToServer=True, stderrToServer=True)\n"})}),(0,i.jsxs)(t.p,{children:["Run your test with ",(0,i.jsx)(t.code,{children:"pants test --debug"})," as usual."]})]}),"\n",(0,i.jsx)(t.h2,{id:"timeouts",children:"Timeouts"}),"\n",(0,i.jsx)(t.p,{children:"Pants can cancel tests which take too long. This is useful to prevent tests from hanging indefinitely."}),"\n",(0,i.jsxs)(t.p,{children:["To add a timeout, set the ",(0,i.jsx)(t.code,{children:"timeout"})," field to an integer value of seconds, like this:"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",metastring:'title="BUILD"',children:'python_test(name="tests", source="tests.py", timeout=120)\n'})}),"\n",(0,i.jsxs)(t.p,{children:["When you set timeout on the ",(0,i.jsx)(t.code,{children:"python_tests"})," target generator, the same timeout will apply to every generated ",(0,i.jsx)(t.code,{children:"python_test"})," target."]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",metastring:'title="BUILD"',children:'python_tests(\n    name="tests",\n    overrides={\n        "test_f1.py": {"timeout": 20},\n        ("test_f2.py", "test_f3.py"): {"timeout": 35},\n    },\n)\n'})}),"\n",(0,i.jsxs)(t.p,{children:["You can also set a default value and a maximum value in ",(0,i.jsx)(t.code,{children:"pants.toml"}),":"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-toml",metastring:'title="pants.toml"',children:"[test]\ntimeout_default = 60\ntimeout_maximum = 600\n"})}),"\n",(0,i.jsxs)(t.p,{children:["If a target sets its ",(0,i.jsx)(t.code,{children:"timeout"})," higher than ",(0,i.jsx)(t.code,{children:"[test].timeout_maximum"}),", Pants will use the value in ",(0,i.jsx)(t.code,{children:"[test].timeout_maximum"}),"."]}),"\n",(0,i.jsxs)(t.admonition,{title:"Tip: temporarily ignoring timeouts",type:"note",children:[(0,i.jsxs)(t.p,{children:["When debugging locally, such as with ",(0,i.jsx)(t.code,{children:"pdb"}),", you might want to temporarily disable timeouts. To do this, set ",(0,i.jsx)(t.code,{children:"--no-test-timeouts"}),":"]}),(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-bash",children:"$ pants test project/app_test.py --no-test-timeouts\n"})})]}),"\n",(0,i.jsx)(t.h2,{id:"test-utilities-and-resources",children:"Test utilities and resources"}),"\n",(0,i.jsx)(t.h3,{id:"test-utilities",children:"Test utilities"}),"\n",(0,i.jsxs)(t.p,{children:["Use the target type ",(0,i.jsx)(t.code,{children:"python_source"})," for test utilities, rather than ",(0,i.jsx)(t.code,{children:"python_test"}),"."]}),"\n",(0,i.jsxs)(t.p,{children:["To reduce boilerplate, you can use either the ",(0,i.jsx)(t.a,{href:"/2.18/reference/targets/python_sources",children:(0,i.jsx)(t.code,{children:"python_sources"})})," or ",(0,i.jsx)(t.a,{href:"/2.18/reference/targets/python_test_utils",children:(0,i.jsx)(t.code,{children:"python_test_utils"})})," targets to generate ",(0,i.jsx)(t.code,{children:"python_source"})," targets. These behave the same, except that ",(0,i.jsx)(t.code,{children:"python_test_utils"})," has a different default ",(0,i.jsx)(t.code,{children:"sources"})," to include ",(0,i.jsx)(t.code,{children:"conftest.py"})," and type stubs for tests (like ",(0,i.jsx)(t.code,{children:"test_foo.pyi"}),"). Use ",(0,i.jsx)(t.a,{href:"/2.18/docs/getting-started/initial-configuration#5-generate-build-files",children:(0,i.jsx)(t.code,{children:"pants tailor ::"})})," to generate both these targets automatically."]}),"\n",(0,i.jsx)(t.p,{children:"For example:"}),"\n",(0,i.jsxs)(o.A,{groupId:"code-examples",children:[(0,i.jsx)(l.A,{value:"helloworld/build",label:"helloworld/BUILD",children:(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",metastring:'tab={"label":"helloworld/BUILD"}',children:'# The default `sources` includes all files other than\n# `!*_test.py`, `!test_*.py`, and `tests.py`, and `conftest.py`.\npython_sources(name="lib")\n\n# We leave off the `dependencies` field because Pants will infer\n# it based on import statements.\npython_tests(name="tests")\n'})})}),(0,i.jsx)(l.A,{value:"helloworld/testutils.py",label:"helloworld/testutils.py",children:(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",metastring:'tab={"label":"helloworld/testutils.py"}',children:"...\n\n@contextmanager\ndef setup_tmpdir(files: Mapping[str, str]) -> Iterator[str]:\n    with temporary_dir() as tmpdir:\n        ...\n        yield rel_tmpdir\n"})})}),(0,i.jsx)(l.A,{value:"helloworld/app_test.py",label:"helloworld/app_test.py",children:(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",metastring:'tab={"label":"helloworld/app_test.py"}',children:'from helloworld.testutils import setup_tmpdir\n\ndef test_app() -> None:\n    with setup_tmpdir({"f.py": "print(\'hello\')"}):\n       assert ...\n'})})})]}),"\n",(0,i.jsx)(t.h3,{id:"assets",children:"Assets"}),"\n",(0,i.jsxs)(t.p,{children:["Refer to ",(0,i.jsx)(t.a,{href:"/2.18/docs/using-pants/assets-and-archives",children:"Assets"})," for how to include asset files in your tests by adding to the ",(0,i.jsx)(t.code,{children:"dependencies"})," field."]}),"\n",(0,i.jsxs)(t.p,{children:["It's often most convenient to use ",(0,i.jsx)(t.code,{children:"file"})," / ",(0,i.jsx)(t.code,{children:"files"})," and ",(0,i.jsx)(t.code,{children:"relocated_files"})," targets in your test code, although you can also use ",(0,i.jsx)(t.code,{children:"resource"})," / ",(0,i.jsx)(t.code,{children:"resources"})," targets."]}),"\n",(0,i.jsx)(t.h2,{id:"testing-your-packaging-pipeline",children:"Testing your packaging pipeline"}),"\n",(0,i.jsxs)(t.p,{children:["You can include the result of ",(0,i.jsx)(t.code,{children:"pants package"})," in your test through the ",(0,i.jsx)(t.code,{children:"runtime_package_dependencies"})," field. Pants will run the equivalent of ",(0,i.jsx)(t.code,{children:"pants package"})," beforehand and copy the built artifact into the test's chroot, allowing you to test things like that the artifact has the correct files present and that it's executable."]}),"\n",(0,i.jsxs)(t.p,{children:["This allows you to test your packaging pipeline by simply running ",(0,i.jsx)(t.code,{children:"pants test ::"}),", without needing custom integration test scripts."]}),"\n",(0,i.jsxs)(t.p,{children:["To depend on a built package, use the ",(0,i.jsx)(t.code,{children:"runtime_package_dependencies"})," field on the ",(0,i.jsx)(t.code,{children:"python_test"})," / ",(0,i.jsx)(t.code,{children:"python_tests"})," target, which is a list of addresses to targets that can be built with ",(0,i.jsx)(t.code,{children:"pants package"}),", such as ",(0,i.jsx)(t.code,{children:"pex_binary"}),", ",(0,i.jsx)(t.code,{children:"python_aws_lambda_function"}),", and ",(0,i.jsx)(t.code,{children:"archive"})," targets. Pants will build the package before running your test, and insert the file into the test's chroot. It will use the same name it would normally use with ",(0,i.jsx)(t.code,{children:"pants package"}),", except without the ",(0,i.jsx)(t.code,{children:"dist/"})," prefix (set by the ",(0,i.jsx)(t.code,{children:"output_path"})," field)."]}),"\n",(0,i.jsx)(t.p,{children:"For example:"}),"\n",(0,i.jsxs)(o.A,{groupId:"code-examples",children:[(0,i.jsx)(l.A,{value:"helloworld/build",label:"helloworld/BUILD",children:(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",metastring:'tab={"label":"helloworld/BUILD"}',children:'# This target teaches Pants about our non-test Python files.\npython_sources(name="lib")\n\npex_binary(\n    name="bin",\n    entry_point="say_hello.py",\n)\n\npython_tests(\n    name="tests",\n    runtime_package_dependencies=[":bin"],\n)\n'})})}),(0,i.jsx)(l.A,{value:"helloworld/say_hello.py",label:"helloworld/say_hello.py",children:(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",metastring:'tab={"label":"helloworld/say_hello.py"}',children:'print("Hello, test!")\n'})})}),(0,i.jsx)(l.A,{value:"helloworld/test_binary.py",label:"helloworld/test_binary.py",children:(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",metastring:'tab={"label":"helloworld/test_binary.py"}',children:"import subprocess\n\ndef test_say_hello():\n    assert  b\"Hello, test!\" in subprocess.check_output(['helloworld/bin.pex'])\n"})})})]}),"\n",(0,i.jsx)(t.h2,{id:"coverage",children:"Coverage"}),"\n",(0,i.jsxs)(t.p,{children:["To report coverage using ",(0,i.jsx)(t.a,{href:"https://coverage.readthedocs.io/en/coverage-5.1/",children:(0,i.jsx)(t.code,{children:"Coverage.py"})}),", set the option ",(0,i.jsx)(t.code,{children:"--test-use-coverage"}),":"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-bash",children:"\u276F pants test --use-coverage helloworld/util/lang_test.py\n"})}),"\n",(0,i.jsx)(t.p,{children:"Or to permanently use coverage, set in your config file:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-toml",metastring:'title="pants.ci.toml"',children:"[test]\nuse_coverage = true\n"})}),"\n",(0,i.jsxs)(t.admonition,{title:"Failure to parse files?",type:"caution",children:[(0,i.jsx)(t.p,{children:"Coverage defaults to running with Python 3.6+ when generating a report, which means it may fail to parse Python 2 syntax and Python 3.8+ syntax. You can fix this by changing the interpreter constraints for running Coverage:"}),(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-toml",children:'# pants.toml\n[coverage-py]\ninterpreter_constraints = [">=3.8"]\n'})}),(0,i.jsxs)(t.p,{children:["However, if your repository has some Python 2-only code and some Python 3-only code, you will not be able to choose an interpreter that works with both versions. So, you will need to set up a ",(0,i.jsx)(t.code,{children:".coveragerc"})," config file and set ",(0,i.jsx)(t.code,{children:"ignore_errors = true"})," under ",(0,i.jsx)(t.code,{children:"[report]"}),", like this:"]}),(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{children:"# .coveragerc\n[report]\nignore_errors = true\n"})}),(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.code,{children:"ignore_errors = true"})," means that those files will simply be left off of the final coverage report."]}),(0,i.jsxs)(t.p,{children:["(Pants should autodiscover the config file ",(0,i.jsx)(t.code,{children:".coveragerc"}),". See ",(0,i.jsx)(t.a,{href:"/2.18/reference/subsystems/coverage-py#section-config-discovery",children:"coverage-py"}),".)"]}),(0,i.jsxs)(t.p,{children:["There's a proposal for Pants to fix this by generating multiple reports when necessary: ",(0,i.jsx)(t.a,{href:"https://github.com/pantsbuild/pants/issues/11137",children:"https://github.com/pantsbuild/pants/issues/11137"}),". We'd appreciate your feedback."]})]}),"\n",(0,i.jsxs)(t.p,{children:["Coverage will report data on any files encountered during the tests. You can filter down the results by using the option ",(0,i.jsx)(t.code,{children:"--coverage-py-filter"})," and passing the name(s) of modules you want coverage data for. Each module name is recursive, meaning submodules will be included. For example:"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-bash",children:'\u276F pants test --use-coverage helloworld/util/lang_test.py --coverage-py-filter=helloworld.util\n\u276F pants test --use-coverage helloworld/util/lang_test.py --coverage-py-filter=\'["helloworld.util.lang", "helloworld.util.lang_test"]\'\n'})}),"\n",(0,i.jsxs)(t.admonition,{type:"note",children:[(0,i.jsxs)(t.mdxAdmonitionTitle,{children:["Set ",(0,i.jsx)(t.code,{children:"global_report"})," to include un-encountered files"]}),(0,i.jsx)(t.p,{children:"By default, coverage.py will only report on files encountered during the tests' run. This means\nthat your coverage score may be misleading; even with a score of 100%, you may have files\nwithout any tests."}),(0,i.jsxs)(t.p,{children:["Instead, you can set ",(0,i.jsx)(t.code,{children:"global_report = true"}),":"]}),(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-toml",metastring:'title="pants.toml"',children:"[coverage-py]\nglobal_report = true\n"})}),(0,i.jsxs)(t.p,{children:["Coverage.py will report on ",(0,i.jsx)(t.a,{href:"https://coverage.readthedocs.io/en/6.3.2/source.html",children:"all files it considers importable"}),",\ni.e. files at the root of the tree, or in directories with a ",(0,i.jsx)(t.code,{children:"__init__.py"})," file. It may still omit\nfiles in ",(0,i.jsx)(t.a,{href:"https://peps.python.org/pep-0420/",children:"implicit namespace packages"})," that lack ",(0,i.jsx)(t.code,{children:"__init__.py"})," files.\nThis is a shortcoming of Coverage.py itself."]})]}),"\n",(0,i.jsx)(t.p,{children:"Pants will default to writing the results to the console, but you can also output in HTML, XML, JSON, or the raw SQLite file:"}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-toml",metastring:'title="pants.toml"',children:'[coverage-py]\nreport = ["raw", "xml", "html", "json", "console"]\n'})}),"\n",(0,i.jsxs)(t.p,{children:["You can change the output dir with the ",(0,i.jsx)(t.code,{children:"output_dir"})," option in the ",(0,i.jsx)(t.code,{children:"[coverage-py]"})," scope."]}),"\n",(0,i.jsxs)(t.p,{children:["You may want to set ",(0,i.jsx)(t.code,{children:"[coverage-py].fail_under"})," to cause Pants to gracefully fail if coverage is too low, e.g. ",(0,i.jsx)(t.code,{children:"fail_under = 70"}),"."]}),"\n",(0,i.jsxs)(t.p,{children:["You may use a Coverage config file, e.g. ",(0,i.jsx)(t.code,{children:".coveragerc"})," or ",(0,i.jsx)(t.code,{children:"pyproject.toml"}),". Pants will autodiscover the config file for you, and you can also set ",(0,i.jsx)(t.code,{children:"[coverage-py].config"})," in your ",(0,i.jsx)(t.code,{children:"pants.toml"})," to point to a non-standard location. You must include ",(0,i.jsx)(t.code,{children:"relative_files = true"})," in the ",(0,i.jsx)(t.code,{children:"[run]"})," section for Pants to work."]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-text",metastring:'title=".coveragerc"',children:"[run]\nrelative_files = true\nbranch = true\n"})}),"\n",(0,i.jsxs)(t.p,{children:["When generating HTML, XML, and JSON reports, you can automatically open the reports through the option ",(0,i.jsx)(t.code,{children:"--test-open-coverage"}),"."]}),"\n",(0,i.jsx)(t.h2,{id:"junit-xml-results",children:"JUnit XML results"}),"\n",(0,i.jsxs)(t.p,{children:["Pytest can generate ",(0,i.jsx)(t.a,{href:"https://docs.pytest.org/en/6.2.x/usage.html#creating-junitxml-format-files",children:"JUnit XML result files"}),". This allows you to hook up your results, for example, to dashboards."]}),"\n",(0,i.jsxs)(t.p,{children:["To save JUnit XML result files, set the option ",(0,i.jsx)(t.code,{children:"[test].report"}),", like this:"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-toml",metastring:'title="pants.toml"',children:"[test]\nreport = true\n"})}),"\n",(0,i.jsxs)(t.p,{children:["This will default to writing test reports to ",(0,i.jsx)(t.code,{children:"dist/test/reports"}),". You may also want to set the option ",(0,i.jsx)(t.code,{children:"[pytest].junit_family"})," to change the format. Run ",(0,i.jsx)(t.code,{children:"pants help-advanced pytest"})," for more information."]}),"\n",(0,i.jsx)(t.h2,{id:"customizing-pytest-command-line-options-per-target",children:"Customizing Pytest command line options per target"}),"\n",(0,i.jsxs)(t.p,{children:["You can set ",(0,i.jsx)(t.code,{children:"PYTEST_ADDOPTS"})," environment variable to add your own command line options, like this:"]}),"\n",(0,i.jsx)(t.pre,{children:(0,i.jsx)(t.code,{className:"language-python",metastring:'title="BUILD"',children:'python_tests(\n    name="tests",\n    ...\n    extra_env_vars=[\n        "PYTEST_ADDOPTS=-p myplugin --reuse-db",\n    ],\n    ...\n)\n'})}),"\n",(0,i.jsxs)(t.p,{children:["Take note that Pants uses some CLI args for its internal mechanism of controlling Pytest (",(0,i.jsx)(t.code,{children:"--color"}),", ",(0,i.jsx)(t.code,{children:"--junit-xml"}),", ",(0,i.jsx)(t.code,{children:"junit_family"}),", ",(0,i.jsx)(t.code,{children:"--cov"}),", ",(0,i.jsx)(t.code,{children:"--cov-report"})," and ",(0,i.jsx)(t.code,{children:"--cov-config"}),"). If these options are overridden, Pants Pytest handling may not work correctly. Set these at your own peril!"]}),"\n",(0,i.jsx)(t.h2,{id:"failures-to-collect-tests",children:"Failures to collect tests"}),"\n",(0,i.jsxs)(t.p,{children:[(0,i.jsx)(t.code,{children:"pytest"})," follows ",(0,i.jsx)(t.a,{href:"https://docs.pytest.org/en/7.1.x/explanation/goodpractices.html#conventions-for-python-test-discovery",children:"certain conventions for test discovery"}),", so if no (or only some) tests are run, it may be worth reviewing the documentation. Pants can help you find test modules that would not be collected by ",(0,i.jsx)(t.code,{children:"pytest"}),". For instance, ",(0,i.jsx)(t.code,{children:"pants tailor --check ::"})," command would suggest creating targets for files that are not covered by glob expressions in your ",(0,i.jsx)(t.code,{children:"BUILD"})," files (e.g. if a test module has a typo and is named ",(0,i.jsx)(t.code,{children:"tes_connection.py"}),"). You can also run ",(0,i.jsx)(t.code,{children:"pants --filter-target-type=python_test filedeps <test-dir>::"})," command to list all test files known to Pants and compare the output with the list of files that exist on disk."]}),"\n",(0,i.jsxs)(t.p,{children:["If your tests fail to import the source modules, it may be due to the import mode used by ",(0,i.jsx)(t.code,{children:"pytest"}),", especially if you are using ",(0,i.jsx)(t.a,{href:"https://packaging.python.org/en/latest/guides/packaging-namespace-packages/",children:"namespace packages"}),". Please review ",(0,i.jsx)(t.a,{href:"https://docs.pytest.org/en/7.1.x/explanation/goodpractices.html#choosing-an-import-mode",children:"Choosing an import mode"})," and ",(0,i.jsx)(t.a,{href:"https://docs.pytest.org/en/7.1.x/explanation/pythonpath.html#import-modes",children:"pytest import mechanisms and sys.path/PYTHONPATH"})," to learn more."]})]})}function u(e={}){let{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(p,{...e})}):p(e)}},753348(e,t,s){s.d(t,{A:()=>n});let n={tabItem:"tabItem_mHvh"}},618264(e,t,s){s.d(t,{A:()=>n});let n={tabList:"tabList_sFbf",tabItem:"tabItem_UVfV"}},637180(e,t,s){s.d(t,{A:()=>o});var n=s(886070);s(830758);var i=s(313526),r=s(753348);function o({children:e,hidden:t,className:s}){return(0,n.jsx)("div",{role:"tabpanel",className:(0,i.A)(r.A.tabItem,s),hidden:t,children:e})}},685008(e,t,s){s.d(t,{A:()=>x});var n=s(886070),i=s(830758),r=s(313526),o=s(911212),l=s(274875),a=s(106632),c=s(189223),d=s(618264);function h({className:e,block:t,selectedValue:s,selectValue:i,tabValues:o}){let a=[],{blockElementScrollPositionUntilNextRender:c}=(0,l.a_)(),h=e=>{let t=e.currentTarget,n=o[a.indexOf(t)].value;n!==s&&(c(t),i(n))},p=e=>{let t=null;switch(e.key){case"Enter":h(e);break;case"ArrowRight":{let s=a.indexOf(e.currentTarget)+1;t=a[s]??a[0];break}case"ArrowLeft":{let s=a.indexOf(e.currentTarget)-1;t=a[s]??a[a.length-1]}}t?.focus()};return(0,n.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.A)("tabs",{"tabs--block":t},e),children:o.map(({value:e,label:t,attributes:i})=>(0,n.jsx)("li",{role:"tab",tabIndex:s===e?0:-1,"aria-selected":s===e,ref:e=>{a.push(e)},onKeyDown:p,onClick:h,...i,className:(0,r.A)("tabs__item",d.A.tabItem,i?.className,{"tabs__item--active":s===e}),children:t??e},e))})}function p({lazy:e,children:t,selectedValue:s}){let o=(Array.isArray(t)?t:[t]).filter(Boolean);if(e){let e=o.find(e=>e.props.value===s);return e?(0,i.cloneElement)(e,{className:(0,r.A)("margin-top--md",e.props.className)}):null}return(0,n.jsx)("div",{className:"margin-top--md",children:o.map((e,t)=>(0,i.cloneElement)(e,{key:t,hidden:e.props.value!==s}))})}function u(e){let t=(0,a.u)(e);return(0,n.jsxs)("div",{className:(0,r.A)(o.G.tabs.container,"tabs-container",d.A.tabList),children:[(0,n.jsx)(h,{...t,...e}),(0,n.jsx)(p,{...t,...e})]})}function x(e){let t=(0,c.A)();return(0,n.jsx)(u,{...e,children:(0,a.v)(e.children)},String(t))}},106632(e,t,s){s.d(t,{u:()=>h,v:()=>c});var n=s(830758),i=s(325557),r=s(363717),o=s(125740),l=s(574229),a=s(270367);function c(e){return n.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,n.isValidElement)(e)&&function(e){let{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function d({value:e,tabValues:t}){return t.some(t=>t.value===e)}function h(e){let t,{defaultValue:s,queryString:h=!1,groupId:p}=e,u=function(e){let{values:t,children:s}=e;return(0,n.useMemo)(()=>{let e=t??c(s).map(({props:{value:e,label:t,attributes:s,default:n}})=>({value:e,label:t,attributes:s,default:n})),n=(0,l.XI)(e,(e,t)=>e.value===t.value);if(n.length>0)throw Error(`Docusaurus error: Duplicate values "${n.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`);return e},[t,s])}(e),[x,g]=(0,n.useState)(()=>(function({defaultValue:e,tabValues:t}){if(0===t.length)throw Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!d({value:e,tabValues:t}))throw Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${t.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}let s=t.find(e=>e.default)??t[0];if(!s)throw Error("Unexpected error: 0 tabValues");return s.value})({defaultValue:s,tabValues:u})),[m,y]=function({queryString:e=!1,groupId:t}){let s=(0,i.W6)(),r=function({queryString:e=!1,groupId:t}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!t)throw Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:e,groupId:t});return[(0,o.aZ)(r),(0,n.useCallback)(e=>{if(!r)return;let t=new URLSearchParams(s.location.search);t.set(r,e),s.replace({...s.location,search:t.toString()})},[r,s])]}({queryString:h,groupId:p}),[j,f]=function({groupId:e}){let t=e?`docusaurus.tab.${e}`:null,[s,i]=(0,a.Dv)(t);return[s,(0,n.useCallback)(e=>{t&&i.set(e)},[t,i])]}({groupId:p}),b=d({value:t=m??j,tabValues:u})?t:null;return(0,r.A)(()=>{b&&g(b)},[b]),{selectedValue:x,selectValue:(0,n.useCallback)(e=>{if(!d({value:e,tabValues:u}))throw Error(`Can't select invalid tab value=${e}`);g(e),y(e),f(e)},[y,f,u]),tabValues:u}}},848193(e,t,s){s.d(t,{R:()=>o,x:()=>l});var n=s(830758);let i={},r=n.createContext(i);function o(e){let t=n.useContext(r);return n.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function l(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:o(e.components),n.createElement(r.Provider,{value:t},e.children)}},47849(e){e.exports=JSON.parse('{"id":"docs/python/goals/test","title":"test","description":"Run tests with Pytest.","source":"@site/versioned_docs/version-2.18/docs/python/goals/test.mdx","sourceDirName":"docs/python/goals","slug":"/docs/python/goals/test","permalink":"/2.18/docs/python/goals/test","draft":false,"unlisted":false,"editUrl":"https://github.com/pantsbuild/pants/edit/main/docs/docs/python/goals/test.mdx","tags":[],"version":"2.18","sidebarPosition":7,"frontMatter":{"title":"test","sidebar_position":7},"sidebar":"docsSidebar","previous":{"title":"run","permalink":"/2.18/docs/python/goals/run"},"next":{"title":"Integrations","permalink":"/2.18/docs/python/integrations/"}}')}}]);